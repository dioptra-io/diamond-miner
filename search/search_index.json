{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Introduction","text":"<p>D-Miner is the first Internet-scale system that captures a multipath view of the topology. By combining and adapting state-of-the-art multipath detection and high speed randomized topology discovery techniques, D-Miner permits discovery of the Internet\u2019s multipath topology in 2.5 days<sup>1</sup> when probing at 100kpps.<sup>2</sup></p>"},{"location":"#implementations","title":"Implementations","text":"<p>There are two implementations of Diamond-Miner:</p> <ul> <li><code>diamond-miner-cpp</code> the original implementation in C++ that have been used for the NSDI 2020 paper<sup>2</sup>.   This implementation is not maintained anymore.</li> <li>This implementation, <code>diamond-miner</code>, a rewrite of the core algorithm in Python and ClickHouse SQL.   This implementation is maintained and used in production. It supports IPv4 and IPv6.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Diamond-Miner requires Python 3.10+.</p> <pre><code>pip install diamond-miner\n</code></pre>"},{"location":"#publication","title":"Publication","text":"<p>Diamond-Miner has been presented and published at NSDI 2020. If you use Diamond-Miner, please cite the following paper:</p> <pre><code>@inproceedings {DiamondMiner2020,\n  author = {Kevin Vermeulen and Justin P. Rohrer and Robert Beverly and Olivier Fourmaux and Timur Friedman},\n  title = {Diamond-Miner: Comprehensive Discovery of the Internet{\\textquoteright}s Topology Diamonds },\n  booktitle = {17th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 20)},\n  year = {2020},\n  isbn = {978-1-939133-13-7},\n  address = {Santa Clara, CA},\n  pages = {479--493},\n  url = {https://www.usenix.org/conference/nsdi20/presentation/vermeulen},\n  publisher = {{USENIX} Association},\n  month = feb,\n}\n</code></pre> <ol> <li> <p>As of v0.1.0, diamond-miner can discover the multipath topology in less than a day when probing at 100k pps.\u00a0\u21a9</p> </li> <li> <p>Vermeulen, Kevin, et al. \"Diamond-Miner: Comprehensive Discovery of the Internet's Topology Diamonds.\" 17th USENIX Symposium on Networked Systems Design and Implementation (NSDI 20). 2020.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"dev/","title":"Development","text":"<p>This library is developed on GitHub in the <code>dioptra-io/diamond-miner</code> repository.</p> <pre><code>git clone git@github.com:dioptra-io/diamond-miner.git\ncd diamond-miner/\n\n# Install the dependencies (once)\npoetry install\n\n# Install the pre-commit hooks (once)\npoetry run pre-commit install\n\n# Edit some files...\n\n# Run the tests\npoetry run pytest\n\n# Preview the documentation\npoetry run mkdocs serve --watch diamond_miner --watch docs\n\n# Commit...\n\n# Tag a new version\npoetry run bumpversion patch # or minor/major\n</code></pre>"},{"location":"dev/#test-data","title":"Test data","text":"<p>Most tests require a running instance of ClickHouse with pre-populated tables. To start a ClickHouse server and insert the test data: <pre><code>docker run --rm -d -p 8123:8123 clickhouse/clickhouse-server:22.8\npoetry run python tests/data/insert.py\n</code></pre></p> <p>To use a different server, set the <code>DIAMOND_MINER_TEST_DATABASE_URL</code> environment variable (<code>http://localhost:8123</code> by default).</p>"},{"location":"usage/","title":"Usage","text":"<p>The <code>diamond-miner</code> library contains three principal components:</p> <ul> <li>Database queries that implements most of the algorithms in ClickHouse SQL.</li> <li>Flow mappers, to map between flow IDs and (address, port) offsets.</li> <li>Probe generators, to generate randomized probes on-the-fly.</li> </ul> <p>These components can be pieced together to conduct various kind of topology measurements.</p>"},{"location":"usage/#how-to-run-the-examples","title":"How to run the examples","text":"<p>To run the examples below, you need a running ClickHouse server: <pre><code>docker run --rm -d -p 8123:8123 clickhouse/clickhouse-server:22.8\n</code></pre></p> <p>You also need <code>pycaracal</code> and <code>pych-client</code>. We recommend that you install them in a virtual environment: <pre><code>python -m venv venv\nsource venv/bin/activate\npip install diamond-miner pycaracal pych-client\n</code></pre></p>"},{"location":"usage/#yarrp","title":"Yarrp","text":"<p>Yarrp is a high-speed single-path traceroute tool. Since Diamond-Miner is a generalization of Yarrp, it is easy to re-implement Yarrp with this library.</p> <pre><code>python examples/yarrp.py\n# 2 links discovered\n</code></pre> examples/yarrp.py<pre><code>import logging\nfrom pathlib import Path\nfrom uuid import uuid4\n\nfrom pycaracal import Probe, prober\nfrom pych_client import ClickHouseClient\n\nfrom diamond_miner.format import format_ipv6\nfrom diamond_miner.generators import probe_generator\nfrom diamond_miner.queries import (\n    CreateTables,\n    GetLinks,\n    InsertLinks,\n    InsertPrefixes,\n    InsertResults,\n)\n\n# Configuration\ncredentials = {\n    \"base_url\": \"http://localhost:8123\",\n    \"database\": \"default\",\n    \"username\": \"default\",\n    \"password\": \"\",\n}\nmeasurement_id = str(uuid4())\nresults_filepath = Path(\"results.csv\")\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO)\n\n    # Configure pycaracal\n    config = prober.Config()\n    config.set_output_file_csv(str(results_filepath))\n    config.set_probing_rate(10_000)\n    config.set_sniffer_wait_time(1)\n\n    # Generate ICMP probes towards every /24 in 1.0.0.0/22,\n    # with a single flow per prefix between TTLs 2-32.\n    gen = probe_generator(\n        prefixes=[(\"1.0.0.0/22\", \"icmp\")],\n        flow_ids=range(1),\n        ttls=range(2, 33),\n    )\n\n    # Convert tuples output by `probe_generator` to pycaracal probes.\n    probes = (\n        Probe(format_ipv6(dst_addr), src_port, dst_port, ttl, protocol, 0)\n        for dst_addr, src_port, dst_port, ttl, protocol in gen\n    )\n\n    # Send the probes.\n    # Note that the probes are randomized and sent on-the-fly,\n    # without being buffered in memory.\n    prober_stats, sniffer_stats, pcap_stats = prober.probe(config, probes)\n\n    # Display some statistics from pycaracal.\n    print(f\"{prober_stats.read} probes read\")\n    print(f\"{sniffer_stats.received_count} probes received\")\n\n    with ClickHouseClient(**credentials) as client:\n        # Insert the results into the database\n        CreateTables().execute(client, measurement_id)\n        InsertResults().execute(\n            client, measurement_id, data=results_filepath.read_bytes()\n        )\n        InsertPrefixes().execute(client, measurement_id)\n        InsertLinks().execute(client, measurement_id)\n\n        # Query the results\n        links = GetLinks().execute(client, measurement_id)\n        print(f\"{len(links)} links discovered\")\n</code></pre>"},{"location":"usage/#diamond-miner","title":"Diamond-Miner","text":"<p>Diamond-Miner needs to remember how many probes were sent to each TTL. As such, instead of generating the probes on-the-fly as in the Yarrp example, we first store in the database the number of probes to send at each round, and we then generate a probes file containing one line per probe. This file is given as an input to pycaracal.</p> <pre><code>python examples/diamond-miner.py\n# 8 links discovered\n</code></pre> examples/diamond-miner.py<pre><code>import logging\nfrom pathlib import Path\nfrom uuid import uuid4\n\nfrom pycaracal import prober\nfrom pych_client import ClickHouseClient\n\nfrom diamond_miner.generators import probe_generator_parallel\nfrom diamond_miner.insert import insert_mda_probe_counts, insert_probe_counts\nfrom diamond_miner.queries import (\n    CreateTables,\n    GetLinks,\n    InsertLinks,\n    InsertPrefixes,\n    InsertResults,\n)\n\n# Configuration\ncredentials = {\n    \"base_url\": \"http://localhost:8123\",\n    \"database\": \"default\",\n    \"username\": \"default\",\n    \"password\": \"\",\n}\nmeasurement_id = str(uuid4())\nprobes_filepath = Path(\"probes.csv.zst\")\nresults_filepath = Path(\"results.csv\")\n\n# ICMP traceroute towards every /24 in 1.0.0.0/22 starting with 6 flows per prefix between TTLs 2-32\nprefixes = [(\"1.0.0.0/22\", \"icmp\", range(2, 33), 6)]\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO)\n    with ClickHouseClient(**credentials) as client:\n        CreateTables().execute(client, measurement_id)\n        for round_ in range(1, 10):\n            logging.info(\"round=%s\", round_)\n            if round_ == 1:\n                # Compute the initial probes\n                insert_probe_counts(\n                    client=client,\n                    measurement_id=measurement_id,\n                    round_=1,\n                    prefixes=prefixes,\n                )\n            else:\n                # Insert results from the previous round\n                InsertResults().execute(\n                    client, measurement_id, data=results_filepath.read_bytes()\n                )\n                InsertPrefixes().execute(client, measurement_id)\n                InsertLinks().execute(client, measurement_id)\n                # Compute subsequent probes\n                insert_mda_probe_counts(\n                    client=client,\n                    measurement_id=measurement_id,\n                    previous_round=round_ - 1,\n                )\n\n            # Write the probes to a file\n            n_probes = probe_generator_parallel(\n                filepath=probes_filepath,\n                client=client,\n                measurement_id=measurement_id,\n                round_=round_,\n            )\n            logging.info(\"n_probes=%s\", n_probes)\n            if n_probes == 0:\n                break\n\n            # Send the probes\n            config = prober.Config()\n            config.set_output_file_csv(str(results_filepath))\n            config.set_probing_rate(10_000)\n            config.set_sniffer_wait_time(1)\n            prober.probe(config, str(probes_filepath))\n\n        links = GetLinks().execute(client, measurement_id)\n        print(f\"{len(links)} links discovered\")\n</code></pre>"},{"location":"usage/#scaling-diamond-miner","title":"Scaling Diamond-Miner","text":"<p>You may find the previous example to run slowly for a large number of prefixes and/or results.</p> <ul> <li>To speed up <code>InsertResults</code>, you can first split the input file in multiple parts, and run this query in parallel over each part.</li> <li>To speed up <code>InsertPrefixes</code> and <code>InsertLinks</code>, you can run these queries in parallel over subsets of the probing space. For example:</li> <li><pre><code>from diamond_miner.queries import InsertPrefixes\nfrom diamond_miner.subsets import subsets_for\nfrom pych_client import ClickHouseClient\n\nwith ClickHouseClient() as client:\n    query = InsertPrefixes()\n    # First option: define subsets manually\n    subsets = [\"1.0.0.0/23\", \"1.0.2.0/23\"]\n    # Second option: compute subsets automatically with `subsets_for`\n    subsets = subsets_for(query, client, measurement_id)\n    query.execute_concurrent(client, measurement_id, subsets=subsets, concurrent_requests=8)\n</code></pre></li> </ul> <p>You can see such techniques implemented in Iris source code:</p> <ul> <li><code>iris/commons/clickhouse.py</code></li> <li><code>iris/worker/inner_pipeline/diamond_miner.py</code></li> </ul>"},{"location":"usage/#alternative-probing-tools","title":"Alternative probing tools","text":"<p>This library is designed to work with <code>pycaracal</code> as the probing tool. However, you can use the tool of your choice, such as <code>scamper</code> as long as you can convert the results to the following format: <pre><code>capture_timestamp,probe_protocol,probe_src_addr,probe_dst_addr,probe_src_port,probe_dst_port,probe_ttl,quoted_ttl,reply_src_addr,reply_protocol,reply_icmp_type,reply_icmp_code,reply_ttl,reply_size,reply_mpls_labels,rtt,round\n1658244381,1,::ffff:132.227.78.108,::ffff:1.0.0.1,24000,0,3,1,::ffff:134.157.254.124,1,11,0,253,56,\"[]\",30,1\n1658244381,1,::ffff:132.227.78.108,::ffff:1.0.0.5,24000,0,3,1,::ffff:134.157.254.124,1,11,0,253,56,\"[]\",57,1\n...\n</code></pre></p>"},{"location":"reference/defaults/","title":"Default values","text":""},{"location":"reference/defaults/#diamond_miner.defaults","title":"<code>diamond_miner.defaults</code>","text":"<p>Constants that are used as default values for function's arguments throughout the code.</p>"},{"location":"reference/defaults/#diamond_miner.defaults.DEFAULT_FAILURE_RATE","title":"<code>DEFAULT_FAILURE_RATE = 0.05</code>  <code>module-attribute</code>","text":"<p>Default MDA failure rate.</p>"},{"location":"reference/defaults/#diamond_miner.defaults.DEFAULT_PREFIX_LEN_V4","title":"<code>DEFAULT_PREFIX_LEN_V4 = 24</code>  <code>module-attribute</code>","text":"<p>Default prefix length for IPv4.</p>"},{"location":"reference/defaults/#diamond_miner.defaults.DEFAULT_PREFIX_LEN_V6","title":"<code>DEFAULT_PREFIX_LEN_V6 = 64</code>  <code>module-attribute</code>","text":"<p>Default prefix length for IPv6.</p>"},{"location":"reference/defaults/#diamond_miner.defaults.DEFAULT_PREFIX_SIZE_V4","title":"<code>DEFAULT_PREFIX_SIZE_V4 = 2 ** 32 - DEFAULT_PREFIX_LEN_V4</code>  <code>module-attribute</code>","text":"<p>Default prefix size (number of addresses) for IPv4.</p>"},{"location":"reference/defaults/#diamond_miner.defaults.DEFAULT_PREFIX_SIZE_V6","title":"<code>DEFAULT_PREFIX_SIZE_V6 = 2 ** 128 - DEFAULT_PREFIX_LEN_V6</code>  <code>module-attribute</code>","text":"<p>Default prefix size (number of addresses) for IPv6.</p>"},{"location":"reference/defaults/#diamond_miner.defaults.DEFAULT_PROBE_DST_PORT","title":"<code>DEFAULT_PROBE_DST_PORT = 33434</code>  <code>module-attribute</code>","text":"<p>Default probe destination port. Unused for ICMP probes.</p>"},{"location":"reference/defaults/#diamond_miner.defaults.DEFAULT_PROBE_SRC_PORT","title":"<code>DEFAULT_PROBE_SRC_PORT = 24000</code>  <code>module-attribute</code>","text":"<p>Default probe source port. Encoded in the ICMP checksum field for ICMP probes.</p>"},{"location":"reference/defaults/#diamond_miner.defaults.PROTOCOLS","title":"<code>PROTOCOLS: dict[int | str, int | str] = {1: 'icmp', 17: 'udp', 58: 'icmp6', 'icmp': 1, 'udp': 17, 'icmp6': 58}</code>  <code>module-attribute</code>","text":"<p>Mapping of IP protocol numbers to caracal protocol strings.</p>"},{"location":"reference/defaults/#diamond_miner.defaults.UNIVERSE_SUBSET","title":"<code>UNIVERSE_SUBSET = IPv6Network('::/0')</code>  <code>module-attribute</code>","text":"<p>Set of all possible IP addresses.</p>"},{"location":"reference/generators/","title":"Probe generators","text":""},{"location":"reference/generators/#diamond_miner.generators","title":"<code>diamond_miner.generators</code>","text":""},{"location":"reference/generators/#diamond_miner.generators.probe_generator","title":"<code>probe_generator(prefixes, flow_ids, ttls, *, prefix_len_v4=DEFAULT_PREFIX_LEN_V4, prefix_len_v6=DEFAULT_PREFIX_LEN_V6, probe_src_port=DEFAULT_PROBE_SRC_PORT, probe_dst_port=DEFAULT_PROBE_DST_PORT, mapper_v4=SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V4), mapper_v6=SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V6), seed=None)</code>","text":"<p>Generate a probe for each prefix, flow ID and TTL, in a random order.</p> <p>Parameters:</p> Name Type Description Default <code>prefixes</code> <code>Sequence[tuple[str, str]]</code> <p>A list of (prefix, protocol) tuples. The protocol can be <code>icmp</code>, <code>icmp6</code> or <code>udp</code>.</p> required <code>flow_ids</code> <code>Sequence[int]</code> <p>The flow IDs to probe.</p> required <code>ttls</code> <code>Sequence[int]</code> <p>The TTLs to probe.</p> required <code>prefix_len_v4</code> <code>int</code> <p>The prefix length to which the IPv4 prefixes will be split to.</p> <code>DEFAULT_PREFIX_LEN_V4</code> <code>prefix_len_v6</code> <code>int</code> <p>The prefix length to which the IPv6 prefixes will be split to.</p> <code>DEFAULT_PREFIX_LEN_V6</code> <code>probe_src_port</code> <code>int</code> <p>The minimum source port of the probes (can be incremented by the flow mapper).</p> <code>DEFAULT_PROBE_SRC_PORT</code> <code>probe_dst_port</code> <code>int</code> <p>The destination port of the probes (constant).</p> <code>DEFAULT_PROBE_DST_PORT</code> <code>mapper_v4</code> <code>FlowMapper</code> <p>The flow mapper for IPv4 probes.</p> <code>SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V4)</code> <code>mapper_v6</code> <code>FlowMapper</code> <p>The flow mapper for IPv6 probes.</p> <code>SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V6)</code> <code>seed</code> <code>int | None</code> <p>The seed of the random permutation (two calls with the same seed will yield the probes in the same order).</p> <code>None</code> <p>Examples:</p> <p>This function is very versatile, it can generate Tokyo-Ping[@pelsser2013paris], Paris-Traceroute[@augustin2006avoiding] or Yarrp-like[@beverly2016yarrp] probes.</p> <p>For ICMP probes, the source port is encoded by caracal in the checksum field of the ICMP header which is generally used by routers for per-flow load-balancing.</p> ICMP ping towards Google DNS servers with 2 flows per address and a TTL of 32<pre><code>prefixes = [(\"8.8.8.8/32\", \"icmp\"), (\"2001:4860:4860::8888/128\", \"icmp6\")]\nprefix_len_v4 = 32\nprefix_len_v6 = 128\nflow_ids = range(2)\nttls = [32]\n\n# When given a prefix size of 1, the sequential flow mapper will only vary the port.\nmapper_v4 = SequentialFlowMapper(prefix_size=1)\nmapper_v6 = SequentialFlowMapper(prefix_size=1)\n</code></pre> ICMP ping towards 1.0.0.0/24 with 1 flow per address and a TTL of 32<pre><code>prefixes = [(\"1.0.0.0/24\", \"icmp\")]\nprefix_len_v4 = 32 # The generator will cut the /24 in 256 /32.\nflow_ids = range(1)\nttls = [32]\n# Same flow mappers as above.\n</code></pre> UDP traceroute towards 1.0.0.0/24 with 2 flows per address<pre><code># 256 addresses * 2 flows * 30 TTLs = 15,360 probes.\nprefixes = [(\"1.0.0.0/24\", \"udp\")]\nprefix_len_v4 = 32 # The generator will cut the /24 in 256 /32.\nflow_ids = range(2)\nttls = range(2, 32)\n# Same flow mappers as above.\n</code></pre> UDP traceroute towards 1.0.0.0/24 with 6 flows **per prefix**<pre><code># 1 prefix * 6 flows * 30 TTLs = 180 probes.\nprefixes = [(\"1.0.0.0/24\", \"udp\")]\nprefix_len_v4 = 24 # We want to target the prefix, not its individual addresses.\nflow_ids = range(6)\nttls = range(2, 32)\n\n# The random flow mapper will assign a random destination (in the /24) to each flow.\nmapper_v4 = RandomFlowMapper(prefix_size=256)\n</code></pre> Source code in <code>diamond_miner/generators/standalone.py</code> <pre><code>def probe_generator(\n    prefixes: Sequence[tuple[str, str]],  # /32 or / 128 if nothing specified\n    flow_ids: Sequence[int],\n    ttls: Sequence[int],\n    *,\n    prefix_len_v4: int = DEFAULT_PREFIX_LEN_V4,\n    prefix_len_v6: int = DEFAULT_PREFIX_LEN_V6,\n    probe_src_port: int = DEFAULT_PROBE_SRC_PORT,\n    probe_dst_port: int = DEFAULT_PROBE_DST_PORT,\n    mapper_v4: FlowMapper = SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V4),\n    mapper_v6: FlowMapper = SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V6),\n    seed: int | None = None,\n) -&gt; Iterator[Probe]:\n    \"\"\"\n    Generate a probe for each prefix, flow ID and TTL, in a random order.\n\n    Args:\n        prefixes: A list of (prefix, protocol) tuples. The protocol can be ``icmp``, ``icmp6`` or ``udp``.\n        flow_ids: The flow IDs to probe.\n        ttls: The TTLs to probe.\n        prefix_len_v4: The prefix length to which the IPv4 prefixes will be split to.\n        prefix_len_v6: The prefix length to which the IPv6 prefixes will be split to.\n        probe_src_port: The minimum source port of the probes (can be incremented by the flow mapper).\n        probe_dst_port: The destination port of the probes (constant).\n        mapper_v4: The flow mapper for IPv4 probes.\n        mapper_v6: The flow mapper for IPv6 probes.\n        seed: The seed of the random permutation (two calls with the same seed will yield the probes in the same order).\n\n    Examples:\n        This function is very versatile, it can generate Tokyo-Ping[@pelsser2013paris],\n        Paris-Traceroute[@augustin2006avoiding] or Yarrp-like[@beverly2016yarrp] probes.\n\n        For ICMP probes, the source port is encoded by caracal in the checksum field of the ICMP header\n        which is generally used by routers for per-flow load-balancing.\n\n        ```python title=\"ICMP ping towards Google DNS servers with 2 flows per address and a TTL of 32\"\n        prefixes = [(\"8.8.8.8/32\", \"icmp\"), (\"2001:4860:4860::8888/128\", \"icmp6\")]\n        prefix_len_v4 = 32\n        prefix_len_v6 = 128\n        flow_ids = range(2)\n        ttls = [32]\n\n        # When given a prefix size of 1, the sequential flow mapper will only vary the port.\n        mapper_v4 = SequentialFlowMapper(prefix_size=1)\n        mapper_v6 = SequentialFlowMapper(prefix_size=1)\n        ```\n\n        ```python title=\"ICMP ping towards 1.0.0.0/24 with 1 flow per address and a TTL of 32\"\n        prefixes = [(\"1.0.0.0/24\", \"icmp\")]\n        prefix_len_v4 = 32 # The generator will cut the /24 in 256 /32.\n        flow_ids = range(1)\n        ttls = [32]\n        # Same flow mappers as above.\n        ```\n\n        ```python title=\"UDP traceroute towards 1.0.0.0/24 with 2 flows per address\"\n        # 256 addresses * 2 flows * 30 TTLs = 15,360 probes.\n        prefixes = [(\"1.0.0.0/24\", \"udp\")]\n        prefix_len_v4 = 32 # The generator will cut the /24 in 256 /32.\n        flow_ids = range(2)\n        ttls = range(2, 32)\n        # Same flow mappers as above.\n        ```\n\n        ```python title=\"UDP traceroute towards 1.0.0.0/24 with 6 flows **per prefix**\"\n        # 1 prefix * 6 flows * 30 TTLs = 180 probes.\n        prefixes = [(\"1.0.0.0/24\", \"udp\")]\n        prefix_len_v4 = 24 # We want to target the prefix, not its individual addresses.\n        flow_ids = range(6)\n        ttls = range(2, 32)\n\n        # The random flow mapper will assign a random destination (in the /24) to each flow.\n        mapper_v4 = RandomFlowMapper(prefix_size=256)\n        ```\n    \"\"\"\n    prefixes_: list[tuple[int, int, int, str]] = []\n    for prefix, protocol in prefixes:\n        for af, subprefix, subprefix_size in split_prefix(\n            prefix, prefix_len_v4, prefix_len_v6\n        ):\n            prefixes_.append((af, subprefix, subprefix_size, protocol))\n\n    grid = ParameterGrid(prefixes_, ttls, flow_ids).shuffled(seed=seed)\n\n    for (af, subprefix, subprefix_size, protocol), ttl, flow_id in grid:\n        mapper = mapper_v4 if af == 4 else mapper_v6\n        addr_offset, port_offset = mapper.offset(flow_id, subprefix)\n        yield subprefix + addr_offset, probe_src_port + port_offset, probe_dst_port, ttl, protocol\n</code></pre>"},{"location":"reference/generators/#diamond_miner.generators.probe_generator_by_flow","title":"<code>probe_generator_by_flow(prefixes, flow_ids, *, prefix_len_v4=DEFAULT_PREFIX_LEN_V4, prefix_len_v6=DEFAULT_PREFIX_LEN_V6, probe_src_port=DEFAULT_PROBE_SRC_PORT, probe_dst_port=DEFAULT_PROBE_DST_PORT, mapper_v4=SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V4), mapper_v6=SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V6), seed=None)</code>","text":"<p>Generate a probe for each prefix, flow id and TTL, in a random order. This function differs from probe_generator in two aspects:</p> <ul> <li>The TTLs are specified for each prefixes, and not globally.</li> <li>All the probes for a given prefix and flow id are generated sequentially.</li> </ul> <p>The parameters and output are identical to probe_generator, excepted for <code>prefixes</code> which is a list of (prefix, protocol, TTLs) tuples, and the absence of the <code>ttls</code> parameter.</p> <p>Parameters:</p> Name Type Description Default <code>prefixes</code> <code>Iterable[tuple[str, str, Iterable[int]]]</code> <p>TODO</p> required Source code in <code>diamond_miner/generators/standalone.py</code> <pre><code>def probe_generator_by_flow(\n    prefixes: Iterable[\n        tuple[str, str, Iterable[int]]\n    ],  # /32 or / 128 if nothing specified\n    flow_ids: Sequence[int],\n    *,\n    prefix_len_v4: int = DEFAULT_PREFIX_LEN_V4,\n    prefix_len_v6: int = DEFAULT_PREFIX_LEN_V6,\n    probe_src_port: int = DEFAULT_PROBE_SRC_PORT,\n    probe_dst_port: int = DEFAULT_PROBE_DST_PORT,\n    mapper_v4: FlowMapper = SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V4),\n    mapper_v6: FlowMapper = SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V6),\n    seed: int | None = None,\n) -&gt; Iterator[Probe]:\n    \"\"\"\n    Generate a probe for each prefix, flow id and TTL, in a random order.\n    This function differs from [probe_generator][diamond_miner.generators.probe_generator] in two aspects:\n\n    - The TTLs are specified for each prefixes, and not globally.\n    - All the probes for a given prefix and flow id are generated sequentially.\n\n    The parameters and output are identical to [probe_generator][diamond_miner.generators.probe_generator],\n    excepted for `prefixes` which is a list of (prefix, protocol, TTLs) tuples,\n    and the absence of the `ttls` parameter.\n\n    Args:\n        prefixes: TODO\n    \"\"\"\n    prefixes_: list[tuple[int, int, int, str, Iterable[int]]] = []\n    for prefix, protocol, ttls in prefixes:\n        for af, subprefix, subprefix_size in split_prefix(\n            prefix, prefix_len_v4, prefix_len_v6\n        ):\n            prefixes_.append((af, subprefix, subprefix_size, protocol, ttls))\n\n    grid = ParameterGrid(prefixes_, flow_ids).shuffled(seed=seed)\n\n    for (af, subprefix, subprefix_size, protocol, ttls), flow_id in grid:\n        mapper = mapper_v4 if af == 4 else mapper_v6\n        for ttl in ttls:\n            addr_offset, port_offset = mapper.offset(flow_id, subprefix)\n            yield subprefix + addr_offset, probe_src_port + port_offset, probe_dst_port, ttl, protocol\n</code></pre>"},{"location":"reference/generators/#diamond_miner.generators.probe_generator_from_database","title":"<code>probe_generator_from_database(client, measurement_id, round_, *, mapper_v4=SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V4), mapper_v6=SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V6), probe_src_port=DEFAULT_PROBE_SRC_PORT, probe_dst_port=DEFAULT_PROBE_DST_PORT, probe_ttl_geq=None, probe_ttl_leq=None, subsets=(UNIVERSE_SUBSET))</code>","text":"<p>TODO: Doctest, note that this doesn't randomize probes.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from ipaddress import ip_address\n&gt;&gt;&gt; from diamond_miner.insert import insert_probe_counts\n&gt;&gt;&gt; from diamond_miner.test import client, create_tables\n&gt;&gt;&gt; create_tables(client, \"test_probe_gen\")\n&gt;&gt;&gt; insert_probe_counts(client, \"test_probe_gen\", 1, [(\"8.8.0.0/23\", \"icmp\", [1, 2], 2)])\n&gt;&gt;&gt; probes = list(probe_generator_from_database(client, \"test_probe_gen\", 1))\n&gt;&gt;&gt; len(probes)\n8\n&gt;&gt;&gt; (str(ip_address(probes[0][0])), *probes[0][1:])\n('::ffff:8.8.1.0', 24000, 33434, 1, 'icmp')\n</code></pre> Source code in <code>diamond_miner/generators/database.py</code> <pre><code>def probe_generator_from_database(\n    client: ClickHouseClient,\n    measurement_id: str,\n    round_: int,\n    *,\n    mapper_v4: FlowMapper = SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V4),\n    mapper_v6: FlowMapper = SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V6),\n    probe_src_port: int = DEFAULT_PROBE_SRC_PORT,\n    probe_dst_port: int = DEFAULT_PROBE_DST_PORT,\n    probe_ttl_geq: int | None = None,\n    probe_ttl_leq: int | None = None,\n    subsets: Iterable[IPNetwork] = (UNIVERSE_SUBSET,),\n) -&gt; Iterator[Probe]:\n    \"\"\"\n    TODO: Doctest, note that this doesn't randomize probes.\n\n    Examples:\n        &gt;&gt;&gt; from ipaddress import ip_address\n        &gt;&gt;&gt; from diamond_miner.insert import insert_probe_counts\n        &gt;&gt;&gt; from diamond_miner.test import client, create_tables\n        &gt;&gt;&gt; create_tables(client, \"test_probe_gen\")\n        &gt;&gt;&gt; insert_probe_counts(client, \"test_probe_gen\", 1, [(\"8.8.0.0/23\", \"icmp\", [1, 2], 2)])\n        &gt;&gt;&gt; probes = list(probe_generator_from_database(client, \"test_probe_gen\", 1))\n        &gt;&gt;&gt; len(probes)\n        8\n        &gt;&gt;&gt; (str(ip_address(probes[0][0])), *probes[0][1:])\n        ('::ffff:8.8.1.0', 24000, 33434, 1, 'icmp')\n    \"\"\"\n    global max_probes\n    if max_probes == 0:\n        max_probes = 4095 # XXX make this a parameter\n        logger.info(\"capping the number of probes to send at %d\", max_probes)\n\n    rows = GetProbesDiff(\n        round_eq=round_, probe_ttl_geq=probe_ttl_geq, probe_ttl_leq=probe_ttl_leq\n    ).execute_iter(client, measurement_id, subsets=subsets)\n    for row in rows:\n        dst_prefix_int = int(IPv6Address(row[\"probe_dst_prefix\"]))\n        mapper = (\n            mapper_v4 if row[\"probe_dst_prefix\"].startswith(\"::ffff:\") else mapper_v6\n        )\n        protocol_str = PROTOCOLS[row[\"probe_protocol\"]]\n\n        for ttl, total_probes, already_sent in row[\"probes_per_ttl\"]:\n            for flow_id in range(already_sent, total_probes):\n                addr_offset, port_offset = mapper.offset(flow_id, dst_prefix_int)\n                dst_addr = dst_prefix_int + addr_offset\n                src_port = probe_src_port + port_offset\n                # Note that port_offset is actually the number of probes sent after having already sent 256 probes.\n                if port_offset &gt; max_probes:\n                    logger.warning(\"not probing %s after having already sent %d probes\", row, max_probes+256)\n                    break\n                yield dst_addr, src_port, probe_dst_port, ttl, protocol_str  # type: ignore\n</code></pre>"},{"location":"reference/generators/#diamond_miner.generators.probe_generator_parallel","title":"<code>probe_generator_parallel(filepath, client, measurement_id, round_, *, mapper_v4=SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V4), mapper_v6=SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V6), probe_src_port=DEFAULT_PROBE_SRC_PORT, probe_dst_port=DEFAULT_PROBE_DST_PORT, probe_ttl_geq=None, probe_ttl_leq=None, max_open_files=8192, n_workers=max(available_cpus() // 8, 1))</code>","text":"<p>Compute the probes to send given the previously discovered links. This function shuffle the probes on-disk: External-memory shuffling in linear time?</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Output file (Zstd-compressed CSV file); will be overwritten.</p> required <code>client</code> <code>ClickHouseClient</code> <p>ClickHouse client.</p> required <code>measurement_id</code> <code>str</code> <p>Measurement id.</p> required <code>round_</code> <code>int</code> <p>Number of the round for which to generate the probes.</p> required <code>mapper_v4</code> <code>FlowMapper</code> <p>The flow mapper for IPv4 probes.</p> <code>SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V4)</code> <code>mapper_v6</code> <code>FlowMapper</code> <p>The flow mapper for IPv6 probes.</p> <code>SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V6)</code> <code>probe_src_port</code> <code>int</code> <p>The minimum source port of the probes (can be incremented by the flow mapper).</p> <code>DEFAULT_PROBE_SRC_PORT</code> <code>probe_dst_port</code> <code>int</code> <p>The destination port of the probes (constant).</p> <code>DEFAULT_PROBE_DST_PORT</code> Source code in <code>diamond_miner/generators/parallel.py</code> <pre><code>def probe_generator_parallel(\n    filepath: Path,\n    client: ClickHouseClient,\n    measurement_id: str,\n    round_: int,\n    *,\n    mapper_v4: FlowMapper = SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V4),\n    mapper_v6: FlowMapper = SequentialFlowMapper(DEFAULT_PREFIX_SIZE_V6),\n    probe_src_port: int = DEFAULT_PROBE_SRC_PORT,\n    probe_dst_port: int = DEFAULT_PROBE_DST_PORT,\n    probe_ttl_geq: int | None = None,\n    probe_ttl_leq: int | None = None,\n    max_open_files: int = 8192,\n    n_workers: int = max(available_cpus() // 8, 1),\n) -&gt; int:\n    \"\"\"\n    Compute the probes to send given the previously discovered links.\n    This function shuffle the probes on-disk:\n    [External-memory shuffling in linear time?](https://lemire.me/blog/2010/03/15/external-memory-shuffling-in-linear-time/)\n\n    Args:\n        filepath: Output file (Zstd-compressed CSV file); will be overwritten.\n        client: ClickHouse client.\n        measurement_id: Measurement id.\n        round_: Number of the round for which to generate the probes.\n        mapper_v4: The flow mapper for IPv4 probes.\n        mapper_v6: The flow mapper for IPv6 probes.\n        probe_src_port: The minimum source port of the probes (can be incremented by the flow mapper).\n        probe_dst_port: The destination port of the probes (constant).\n\n    \"\"\"\n    # TODO: These subsets are sub-optimal, `CountProbesPerPrefix` should count\n    # the actual number of probes to be sent, not the total number of probes sent.\n    subsets = subsets_for(\n        GetProbesDiff(\n            round_eq=round_, probe_ttl_geq=probe_ttl_geq, probe_ttl_leq=probe_ttl_leq\n        ),\n        client,\n        measurement_id,\n    )\n\n    if not subsets:\n        return 0\n\n    n_files_per_subset = max_open_files // len(subsets)\n\n    logger.info(\n        \"mda_probes n_workers=%s n_subsets=%s n_files_per_subset=%s\",\n        n_workers,\n        len(subsets),\n        n_files_per_subset,\n    )\n\n    with TemporaryDirectory(dir=filepath.parent) as temp_dir:\n        with ProcessPoolExecutor(n_workers) as executor:\n            futures = [\n                executor.submit(\n                    worker,\n                    Path(temp_dir) / f\"subset_{i}\",\n                    client.config,\n                    measurement_id,\n                    round_,\n                    mapper_v4,\n                    mapper_v6,\n                    probe_src_port,\n                    probe_dst_port,\n                    probe_ttl_geq,\n                    probe_ttl_leq,\n                    subset,\n                    n_files_per_subset,\n                )\n                for i, subset in enumerate(subsets)\n            ]\n            n_probes = sum(future.result() for future in as_completed(futures))\n\n        files = list(Path(temp_dir).glob(\"subset_*.csv.zst\"))\n        random.shuffle(files)\n\n        logger.info(\"mda_probes status=merging n_files=%s\", len(files))\n        with filepath.open(\"wb\") as out:\n            for f in files:\n                with f.open(\"rb\") as inp:\n                    shutil.copyfileobj(inp, out)\n\n    return n_probes\n</code></pre>"},{"location":"reference/helpers/","title":"Helpers","text":""},{"location":"reference/helpers/#diamond_miner.format","title":"<code>diamond_miner.format</code>","text":""},{"location":"reference/helpers/#diamond_miner.format.format_ipv6","title":"<code>format_ipv6(addr)</code>","text":"<p>Convert an IPv6 UInt128 to a string.     &gt;&gt;&gt; from diamond_miner.format import format_ipv6     &gt;&gt;&gt; format_ipv6(281470816487432)     '::ffff:8.8.8.8'</p> Source code in <code>diamond_miner/format.py</code> <pre><code>def format_ipv6(addr: int) -&gt; str:\n    \"\"\"\n    Convert an IPv6 UInt128 to a string.\n        &gt;&gt;&gt; from diamond_miner.format import format_ipv6\n        &gt;&gt;&gt; format_ipv6(281470816487432)\n        '::ffff:8.8.8.8'\n    \"\"\"\n    return str(IPv6Address(addr))\n</code></pre>"},{"location":"reference/helpers/#diamond_miner.format.format_probe","title":"<code>format_probe(dst_addr_v6, src_port, dst_port, ttl, protocol)</code>","text":"<p>Create a Caracal probe string. Examples:     &gt;&gt;&gt; from diamond_miner.format import format_probe     &gt;&gt;&gt; format_probe(281470816487432, 24000, 33434, 1, \"icmp\")     '::ffff:8.8.8.8,24000,33434,1,icmp'</p> Source code in <code>diamond_miner/format.py</code> <pre><code>def format_probe(\n    dst_addr_v6: int, src_port: int, dst_port: int, ttl: int, protocol: str\n) -&gt; str:\n    \"\"\"\n    Create a Caracal probe string.\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.format import format_probe\n        &gt;&gt;&gt; format_probe(281470816487432, 24000, 33434, 1, \"icmp\")\n        '::ffff:8.8.8.8,24000,33434,1,icmp'\n    \"\"\"\n    return f\"{format_ipv6(dst_addr_v6)},{src_port},{dst_port},{ttl},{protocol}\"\n</code></pre>"},{"location":"reference/helpers/#diamond_miner.insert","title":"<code>diamond_miner.insert</code>","text":""},{"location":"reference/helpers/#diamond_miner.insert.insert_mda_probe_counts","title":"<code>insert_mda_probe_counts(client, measurement_id, previous_round, adaptive_eps=False, target_epsilon=DEFAULT_FAILURE_RATE, concurrent_requests=max(available_cpus() // 8, 1))</code>","text":"<p>Run the Diamond-Miner algorithm and insert the resulting probes into the probes table.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>ClickHouseClient</code> <p>ClickHouse client.</p> required <code>measurement_id</code> <code>str</code> <p>Measurement id.</p> required <code>previous_round</code> <code>int</code> <p>Round on which to run the Diamond-Miner algorithm.</p> required <code>adaptive_eps</code> <code>bool</code> <p>Set to <code>True</code> to handle nested load-balancers.</p> <code>False</code> <code>target_epsilon</code> <code>float</code> <p>Target failure rate of the MDA algorithm.</p> <code>DEFAULT_FAILURE_RATE</code> <code>concurrent_requests</code> <code>int</code> <p>Maximum number of requests to execute concurrently.</p> <code>max(available_cpus() // 8, 1)</code> Source code in <code>diamond_miner/insert.py</code> <pre><code>def insert_mda_probe_counts(\n    client: ClickHouseClient,\n    measurement_id: str,\n    previous_round: int,\n    adaptive_eps: bool = False,\n    target_epsilon: float = DEFAULT_FAILURE_RATE,\n    concurrent_requests: int = max(available_cpus() // 8, 1),\n) -&gt; None:\n    \"\"\"\n    Run the Diamond-Miner algorithm and insert the resulting probes into the probes table.\n\n    Args:\n        client: ClickHouse client.\n        measurement_id: Measurement id.\n        previous_round: Round on which to run the Diamond-Miner algorithm.\n        adaptive_eps: Set to `True` to handle nested load-balancers.\n        target_epsilon: Target failure rate of the MDA algorithm.\n        concurrent_requests: Maximum number of requests to execute concurrently.\n    \"\"\"\n    # TODO: set filter_partial and filter_virtual to false?\n    query = InsertMDAProbes(\n        adaptive_eps=adaptive_eps,\n        round_leq=previous_round,\n        filter_partial=True,\n        filter_virtual=True,\n        filter_inter_round=True,\n        target_epsilon=target_epsilon,\n    )\n    subsets = subsets_for(query, client, measurement_id)\n    query.execute_concurrent(\n        client, measurement_id, subsets=subsets, concurrent_requests=concurrent_requests\n    )\n</code></pre>"},{"location":"reference/helpers/#diamond_miner.insert.insert_probe_counts","title":"<code>insert_probe_counts(client, measurement_id, round_, prefixes, prefix_len_v4=DEFAULT_PREFIX_LEN_V4, prefix_len_v6=DEFAULT_PREFIX_LEN_V6)</code>","text":"<p>Insert the probe counts specified by <code>prefixes</code> into the probes table.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>ClickHouseClient</code> <p>ClickHouse client.</p> required <code>measurement_id</code> <code>str</code> <p>Measurement id.</p> required <code>round_</code> <code>int</code> <p>Round number for which to insert the probe counts.</p> required <code>prefixes</code> <code>Iterable[tuple[str, str, Iterable[int], int]]</code> <p>A list of <code>(prefix, protocol, ttls, n_probes)</code> tuples. /32 or /128 is assumed if not specified.</p> required <code>prefix_len_v4</code> <code>int</code> <p>The prefix length to which the IPv4 prefixes will be split to.</p> <code>DEFAULT_PREFIX_LEN_V4</code> <code>prefix_len_v6</code> <code>int</code> <p>The prefix length to which the IPv6 prefixes will be split to.</p> <code>DEFAULT_PREFIX_LEN_V6</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client, create_tables\n&gt;&gt;&gt; from diamond_miner.queries import GetProbes\n&gt;&gt;&gt; create_tables(client, \"test_probe_counts\")\n&gt;&gt;&gt; insert_probe_counts(client, \"test_probe_counts\", 1, [(\"8.8.0.0/22\", \"icmp\", range(2, 5), 6)])\n&gt;&gt;&gt; rows = sorted(GetProbes(round_eq=1).execute(client, \"test_probe_counts\"), key=lambda x: x[\"probe_dst_prefix\"])\n&gt;&gt;&gt; len(rows)\n4\n&gt;&gt;&gt; row = rows[0]\n&gt;&gt;&gt; row[\"probe_dst_prefix\"]\n'::ffff:8.8.0.0'\n&gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n[[2, 6], [3, 6], [4, 6]]\n&gt;&gt;&gt; row = rows[1]\n&gt;&gt;&gt; row[\"probe_dst_prefix\"]\n'::ffff:8.8.1.0'\n&gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n[[2, 6], [3, 6], [4, 6]]\n</code></pre> Source code in <code>diamond_miner/insert.py</code> <pre><code>def insert_probe_counts(\n    client: ClickHouseClient,\n    measurement_id: str,\n    round_: int,\n    prefixes: Iterable[tuple[str, str, Iterable[int], int]],\n    prefix_len_v4: int = DEFAULT_PREFIX_LEN_V4,\n    prefix_len_v6: int = DEFAULT_PREFIX_LEN_V6,\n) -&gt; None:\n    \"\"\"\n    Insert the probe counts specified by `prefixes` into the probes table.\n\n    Args:\n        client: ClickHouse client.\n        measurement_id: Measurement id.\n        round_: Round number for which to insert the probe counts.\n        prefixes: A list of `(prefix, protocol, ttls, n_probes)` tuples. /32 or /128 is assumed if not specified.\n        prefix_len_v4: The prefix length to which the IPv4 prefixes will be split to.\n        prefix_len_v6: The prefix length to which the IPv6 prefixes will be split to.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client, create_tables\n        &gt;&gt;&gt; from diamond_miner.queries import GetProbes\n        &gt;&gt;&gt; create_tables(client, \"test_probe_counts\")\n        &gt;&gt;&gt; insert_probe_counts(client, \"test_probe_counts\", 1, [(\"8.8.0.0/22\", \"icmp\", range(2, 5), 6)])\n        &gt;&gt;&gt; rows = sorted(GetProbes(round_eq=1).execute(client, \"test_probe_counts\"), key=lambda x: x[\"probe_dst_prefix\"])\n        &gt;&gt;&gt; len(rows)\n        4\n        &gt;&gt;&gt; row = rows[0]\n        &gt;&gt;&gt; row[\"probe_dst_prefix\"]\n        '::ffff:8.8.0.0'\n        &gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n        [[2, 6], [3, 6], [4, 6]]\n        &gt;&gt;&gt; row = rows[1]\n        &gt;&gt;&gt; row[\"probe_dst_prefix\"]\n        '::ffff:8.8.1.0'\n        &gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n        [[2, 6], [3, 6], [4, 6]]\n    \"\"\"\n\n    def gen() -&gt; Iterator[bytes]:\n        for prefix, protocol, ttls, n_probes in prefixes:\n            protocol = PROTOCOLS[protocol]  # type: ignore\n            for af, subprefix, subprefix_size in split_prefix(\n                prefix, prefix_len_v4, prefix_len_v6\n            ):\n                yield \"\\n\".join(\n                    f'[{protocol},\"{format_ipv6(subprefix)}\",{ttl},{n_probes},{round_}]'\n                    for ttl in ttls\n                ).encode()\n\n    InsertProbes().execute(client, measurement_id, data=gen())\n</code></pre>"},{"location":"reference/helpers/#diamond_miner.mda","title":"<code>diamond_miner.mda</code>","text":""},{"location":"reference/helpers/#diamond_miner.mda.stopping_point","title":"<code>stopping_point(k, eps=DEFAULT_FAILURE_RATE)</code>","text":"<p>Return the number <code>n_k</code> of probes that guarantees that the probability of not detecting <code>k</code> outgoing load-balanced edges is lower than <code>eps</code>[@veitch2009failure;@jacquet2018collecter].</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; stopping_point(1, 0.05)\n0\n&gt;&gt;&gt; stopping_point(2, 0.05)\n6\n&gt;&gt;&gt; stopping_point(3, 0.05)\n11\n&gt;&gt;&gt; stopping_point(11, 0.05)\n57\n&gt;&gt;&gt; stopping_point(101, 0.05)\n765\n</code></pre> Note <p>There is a typo in the D-Miner paper: n(101) = 765, not 757.</p> Source code in <code>diamond_miner/mda.py</code> <pre><code>def stopping_point(k: int, eps: float = DEFAULT_FAILURE_RATE) -&gt; int:\n    \"\"\"\n    Return the number `n_k` of probes that guarantees that the probability of not\n    detecting `k` outgoing load-balanced edges is lower than `eps`[@veitch2009failure;@jacquet2018collecter].\n\n    Examples:\n        &gt;&gt;&gt; stopping_point(1, 0.05)\n        0\n        &gt;&gt;&gt; stopping_point(2, 0.05)\n        6\n        &gt;&gt;&gt; stopping_point(3, 0.05)\n        11\n        &gt;&gt;&gt; stopping_point(11, 0.05)\n        57\n        &gt;&gt;&gt; stopping_point(101, 0.05)\n        765\n\n    Note:\n        There is a typo in the D-Miner paper: n(101) = 765, not 757.\n    \"\"\"\n    assert (k &gt;= 1) and (0 &lt;= eps &lt;= 1)\n    if k == 1:\n        return 0\n    return ceil(log(eps / k) / log((k - 1) / k))\n</code></pre>"},{"location":"reference/helpers/#diamond_miner.subsets","title":"<code>diamond_miner.subsets</code>","text":""},{"location":"reference/helpers/#diamond_miner.subsets.addr_to_network","title":"<code>addr_to_network(addr, prefix_len_v4, prefix_len_v6)</code>","text":"<p>Examples:</p> <pre><code>&gt;&gt;&gt; addr_to_network(\"::ffff:8.8.8.0\", 24, 64)\nIPv6Network('::ffff:8.8.8.0/120')\n&gt;&gt;&gt; addr_to_network(\"2001:4860:4860:1234::\", 24, 64)\nIPv6Network('2001:4860:4860:1234::/64')\n</code></pre> Source code in <code>diamond_miner/subsets.py</code> <pre><code>def addr_to_network(addr: str, prefix_len_v4: int, prefix_len_v6: int) -&gt; IPv6Network:\n    \"\"\"\n    Examples:\n        &gt;&gt;&gt; addr_to_network(\"::ffff:8.8.8.0\", 24, 64)\n        IPv6Network('::ffff:8.8.8.0/120')\n        &gt;&gt;&gt; addr_to_network(\"2001:4860:4860:1234::\", 24, 64)\n        IPv6Network('2001:4860:4860:1234::/64')\n    \"\"\"\n    assert \":\" in addr, \"`addr` must be an (IPv4-mapped) IPv6 address.\"\n    if addr.startswith(\"::ffff:\"):\n        return IPv6Network(f\"{addr}/{96+prefix_len_v4}\")\n    return IPv6Network(f\"{addr}/{prefix_len_v6}\")\n</code></pre>"},{"location":"reference/helpers/#diamond_miner.subsets.is_subnet_of","title":"<code>is_subnet_of(a, b)</code>","text":"<p>A faster version of IPv6Network.subnet_of(other).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_subnet_of(IPv6Network(\"1000::/16\"), IPv6Network(\"1000::/16\"))\nTrue\n&gt;&gt;&gt; is_subnet_of(IPv6Network(\"1000::/17\"), IPv6Network(\"1000::/16\"))\nTrue\n&gt;&gt;&gt; is_subnet_of(IPv6Network(\"1000::/15\"), IPv6Network(\"1000::/16\"))\nFalse\n&gt;&gt;&gt; is_subnet_of(IPv6Network(\"1000::/16\"), IPv6Network(\"2000::/16\"))\nFalse\n</code></pre> Source code in <code>diamond_miner/subsets.py</code> <pre><code>def is_subnet_of(a: IPv6Network, b: IPv6Network) -&gt; bool:\n    \"\"\"\n    A faster version of IPv6Network.subnet_of(other).\n\n    Examples:\n        &gt;&gt;&gt; is_subnet_of(IPv6Network(\"1000::/16\"), IPv6Network(\"1000::/16\"))\n        True\n        &gt;&gt;&gt; is_subnet_of(IPv6Network(\"1000::/17\"), IPv6Network(\"1000::/16\"))\n        True\n        &gt;&gt;&gt; is_subnet_of(IPv6Network(\"1000::/15\"), IPv6Network(\"1000::/16\"))\n        False\n        &gt;&gt;&gt; is_subnet_of(IPv6Network(\"1000::/16\"), IPv6Network(\"2000::/16\"))\n        False\n    \"\"\"\n    a_net = a.network_address._ip  # type: ignore\n    b_net = b.network_address._ip  # type: ignore\n    if b_net &lt;= a_net:\n        a_brd = a_net | (a.netmask._ip ^ ALL_ONES_V6)  # type: ignore\n        b_brd = b_net | (b.netmask._ip ^ ALL_ONES_V6)  # type: ignore\n        return b_brd &gt;= a_brd  # type: ignore\n    return False\n</code></pre>"},{"location":"reference/helpers/#diamond_miner.subsets.n_items","title":"<code>n_items(counts, subset)</code>","text":"<p>Examples:</p> <pre><code>&gt;&gt;&gt; counts = {IPv6Network(\"1000::/16\"): 2, IPv6Network(\"8000::/16\"): 10}\n&gt;&gt;&gt; n_items(counts, IPv6Network(\"0000::/1\"))\n2\n&gt;&gt;&gt; n_items(counts, IPv6Network(\"8000::/1\"))\n10\n&gt;&gt;&gt; n_items(counts, IPv6Network(\"::/0\"))\n12\n</code></pre> Source code in <code>diamond_miner/subsets.py</code> <pre><code>def n_items(counts: Counts, subset: IPv6Network) -&gt; int:\n    \"\"\"\n    Examples:\n        &gt;&gt;&gt; counts = {IPv6Network(\"1000::/16\"): 2, IPv6Network(\"8000::/16\"): 10}\n        &gt;&gt;&gt; n_items(counts, IPv6Network(\"0000::/1\"))\n        2\n        &gt;&gt;&gt; n_items(counts, IPv6Network(\"8000::/1\"))\n        10\n        &gt;&gt;&gt; n_items(counts, IPv6Network(\"::/0\"))\n        12\n    \"\"\"\n    total = 0\n    for network, count in counts.items():\n        if is_subnet_of(network, subset):\n            total += count\n    return total\n</code></pre>"},{"location":"reference/helpers/#diamond_miner.subsets.split","title":"<code>split(counts, max_items_per_subset)</code>","text":"<p>Return the IP networks such that there are no more than <code>max_items_per_subset</code> per network.</p> <p>Parameters:</p> Name Type Description Default <code>counts</code> <code>Counts</code> <p>Number of items per prefix in the database table.</p> required <code>max_items_per_subset</code> <code>int</code> <p>Maximum number of items per network.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; counts = {IPv6Network(\"::ffff:8.8.4.0/120\"): 10, IPv6Network(\"::ffff:8.8.8.0/120\"): 5}\n&gt;&gt;&gt; split(counts, 15)\n[IPv6Network('::/0')]\n&gt;&gt;&gt; split(counts, 10)\n[IPv6Network('::ffff:8.8.0.0/117'), IPv6Network('::ffff:8.8.8.0/117')]\n&gt;&gt;&gt; split(counts, 1) # Impossible case, should return the minimal feasible networks.\n[IPv6Network('::ffff:8.8.4.0/120'), IPv6Network('::ffff:8.8.8.0/120')]\n&gt;&gt;&gt; split({}, 10)\n[]\n</code></pre> Source code in <code>diamond_miner/subsets.py</code> <pre><code>def split(counts: Counts, max_items_per_subset: int) -&gt; list[IPv6Network]:\n    \"\"\"\n    Return the IP networks such that there are no more than `max_items_per_subset`\n    per network.\n\n    Args:\n        counts: Number of items per prefix in the database table.\n        max_items_per_subset: Maximum number of items per network.\n\n    Examples:\n        &gt;&gt;&gt; counts = {IPv6Network(\"::ffff:8.8.4.0/120\"): 10, IPv6Network(\"::ffff:8.8.8.0/120\"): 5}\n        &gt;&gt;&gt; split(counts, 15)\n        [IPv6Network('::/0')]\n        &gt;&gt;&gt; split(counts, 10)\n        [IPv6Network('::ffff:8.8.0.0/117'), IPv6Network('::ffff:8.8.8.0/117')]\n        &gt;&gt;&gt; split(counts, 1) # Impossible case, should return the minimal feasible networks.\n        [IPv6Network('::ffff:8.8.4.0/120'), IPv6Network('::ffff:8.8.8.0/120')]\n        &gt;&gt;&gt; split({}, 10)\n        []\n    \"\"\"\n    candidates = [(IPv6Network(\"::/0\"), n_items(counts, IPv6Network(\"::/0\")))]\n    subsets = []\n\n    while candidates:\n        candidate, n_replies = candidates.pop()\n        if max_items_per_subset &gt;= n_replies &gt; 0:\n            subsets.append(candidate)\n        elif n_replies &gt; 0:\n            a, b = tuple(candidate.subnets(prefixlen_diff=1))\n            n_items_a = n_items(counts, a)\n            n_items_b = n_items(counts, b)\n            if n_items_a + n_items_b == 0:\n                subsets.append(candidate)\n            else:\n                candidates.append((a, n_items_a))\n                candidates.append((b, n_items_b))\n\n    return sorted(subsets)\n</code></pre>"},{"location":"reference/helpers/#diamond_miner.subsets.subsets_for","title":"<code>subsets_for(query, client, measurement_id, *, max_items_per_subset=8000000)</code>","text":"<p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import GetLinks, GetProbes, GetResults\n&gt;&gt;&gt; subsets_for(GetLinks(), client, 'test_nsdi_example', max_items_per_subset=1)\n[IPv6Network('::ffff:200.0.0.0/112')]\n&gt;&gt;&gt; subsets_for(GetProbes(round_eq=1), client, 'test_nsdi_example', max_items_per_subset=1)\n[IPv6Network('::ffff:200.0.0.0/112')]\n&gt;&gt;&gt; subsets_for(GetResults(), client, 'test_nsdi_example', max_items_per_subset=1)\n[IPv6Network('::ffff:200.0.0.0/112')]\n</code></pre> Source code in <code>diamond_miner/subsets.py</code> <pre><code>def subsets_for(\n    query: LinksQuery | ProbesQuery | ResultsQuery,\n    client: ClickHouseClient,\n    measurement_id: str,\n    *,\n    max_items_per_subset: int = 8_000_000,\n) -&gt; list[IPv6Network]:\n    \"\"\"\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import GetLinks, GetProbes, GetResults\n        &gt;&gt;&gt; subsets_for(GetLinks(), client, 'test_nsdi_example', max_items_per_subset=1)\n        [IPv6Network('::ffff:200.0.0.0/112')]\n        &gt;&gt;&gt; subsets_for(GetProbes(round_eq=1), client, 'test_nsdi_example', max_items_per_subset=1)\n        [IPv6Network('::ffff:200.0.0.0/112')]\n        &gt;&gt;&gt; subsets_for(GetResults(), client, 'test_nsdi_example', max_items_per_subset=1)\n        [IPv6Network('::ffff:200.0.0.0/112')]\n    \"\"\"\n    if isinstance(query, LinksQuery):\n        count_query = CountLinksPerPrefix(**common_parameters(query, LinksQuery))\n    elif isinstance(query, ProbesQuery):\n        count_query = CountProbesPerPrefix(**common_parameters(query, ProbesQuery))  # type: ignore\n    elif isinstance(query, ResultsQuery):\n        count_query = CountResultsPerPrefix(**common_parameters(query, ResultsQuery))  # type: ignore\n    else:\n        raise NotImplementedError\n    counts = {\n        addr_to_network(\n            row[\"prefix\"], count_query.prefix_len_v4, count_query.prefix_len_v6\n        ): row[\"count\"]\n        for row in count_query.execute_iter(client, measurement_id)\n    }\n    return split(counts, max_items_per_subset)\n</code></pre>"},{"location":"reference/mappers/","title":"Flow mappers","text":""},{"location":"reference/mappers/#diamond_miner.mappers","title":"<code>diamond_miner.mappers</code>","text":"<p>Functions for mapping flow IDs to addresses and ports. We make the flow ID start at 0. <code>prefix_size</code> is the number of addresses in the prefix: <code>2 ** (32 - 24)</code> for a /24 in IPv4.</p>"},{"location":"reference/mappers/#diamond_miner.mappers.IntervalFlowMapper","title":"<code>IntervalFlowMapper</code>","text":"<p>Similar to the <code>SequentialFlowMapper</code> but with an increment &gt;= 1. This allows to target addresses .1, .33, .65, ... in priority, which are more likely to respond to probes[@fan2010selecting].</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.mappers import IntervalFlowMapper\n&gt;&gt;&gt; mapper = IntervalFlowMapper()\n&gt;&gt;&gt; mapper.offset(1)\n(33, 0)\n</code></pre> Source code in <code>diamond_miner/mappers.py</code> <pre><code>class IntervalFlowMapper:\n    \"\"\"\n    Similar to the `SequentialFlowMapper` but with an increment &gt;= 1.\n    This allows to target addresses .1, .33, .65, ... in priority,\n    which are more likely to respond to probes[@fan2010selecting].\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.mappers import IntervalFlowMapper\n        &gt;&gt;&gt; mapper = IntervalFlowMapper()\n        &gt;&gt;&gt; mapper.offset(1)\n        (33, 0)\n    \"\"\"\n\n    def __init__(self, prefix_size: int = DEFAULT_PREFIX_SIZE_V4, step: int = 32):\n        assert prefix_size &gt; 0, \"prefix_size must be positive.\"\n        assert prefix_size % 2 == 0, \"prefix_size must be pair.\"\n        assert step &gt; 0, \"step must be positive.\"\n        assert step % 2 == 0, \"step must be pair.\"\n        self.period = prefix_size // step\n        self.prefix_size = prefix_size\n        self.step = step\n\n    def flow_id(self, addr_offset: int, port_offset: int, prefix: int = 0) -&gt; int:\n        if addr_offset == 0:\n            return self.prefix_size - 1\n        if port_offset != 0:\n            return self.prefix_size + port_offset - 1\n        q, r = divmod(addr_offset - 1, self.step)\n        return r * self.period + q\n\n    def offset(self, flow_id: int, prefix: int = 0) -&gt; tuple[int, int]:\n        if flow_id &lt; self.prefix_size - 1:\n            return ((flow_id * self.step) % (self.prefix_size - 1)) + 1, 0\n        if flow_id == self.prefix_size - 1:\n            return 0, 0\n        return self.prefix_size - 1, flow_id - self.prefix_size + 1\n</code></pre>"},{"location":"reference/mappers/#diamond_miner.mappers.RandomFlowMapper","title":"<code>RandomFlowMapper</code>","text":"<p>Similar to the <code>SequentialFlowMapper</code> but with a random mapping between flow IDs and addresses. The mapping is randomized by prefix.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.mappers import RandomFlowMapper\n&gt;&gt;&gt; mapper = RandomFlowMapper(seed=2022)\n&gt;&gt;&gt; mapper.offset(1, prefix=1)\n(34, 0)\n&gt;&gt;&gt; mapper.offset(1, prefix=2)\n(145, 0)\n</code></pre> Source code in <code>diamond_miner/mappers.py</code> <pre><code>class RandomFlowMapper:\n    \"\"\"\n    Similar to the `SequentialFlowMapper` but with a random mapping between flow IDs and addresses.\n    The mapping is randomized by prefix.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.mappers import RandomFlowMapper\n        &gt;&gt;&gt; mapper = RandomFlowMapper(seed=2022)\n        &gt;&gt;&gt; mapper.offset(1, prefix=1)\n        (34, 0)\n        &gt;&gt;&gt; mapper.offset(1, prefix=2)\n        (145, 0)\n    \"\"\"\n\n    def __init__(self, seed: int, prefix_size: int = DEFAULT_PREFIX_SIZE_V4):\n        # We can generate a random permutation up to 2^64-1 only.\n        assert prefix_size &gt; 0, \"prefix_size must be positive.\"\n        self.permutations = []\n        self.prefix_size = min(prefix_size, (2**64) - 1)\n        random.seed(seed)\n        for i in range(1024):\n            perm = Permutation(self.prefix_size, 3, random.randint(0, 2**64))\n            self.permutations.append(perm)\n\n    def flow_id(self, addr_offset: int, port_offset: int, prefix: int) -&gt; int:\n        assert addr_offset &lt; self.prefix_size\n        if port_offset != 0:\n            return self.prefix_size + port_offset - 1\n        perm = self.permutations[prefix % len(self.permutations)]\n        return perm.inv(addr_offset)  # type: ignore\n\n    def offset(self, flow_id: int, prefix: int) -&gt; tuple[int, int]:\n        if flow_id &lt; self.prefix_size:\n            perm = self.permutations[prefix % len(self.permutations)]\n            return perm[flow_id], 0\n        else:\n            return self.prefix_size - 1, flow_id - self.prefix_size + 1\n</code></pre>"},{"location":"reference/mappers/#diamond_miner.mappers.ReverseByteFlowMapper","title":"<code>ReverseByteFlowMapper</code>","text":"<p>Maps flow <code>n</code> to address <code>reverse(n)</code> until we have done the whole prefix. It then increases the port number sequentially.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.mappers import ReverseByteFlowMapper\n&gt;&gt;&gt; mapper = ReverseByteFlowMapper()\n&gt;&gt;&gt; mapper.offset(1)\n(129, 0)\n</code></pre> Source code in <code>diamond_miner/mappers.py</code> <pre><code>class ReverseByteFlowMapper:\n    \"\"\"\n    Maps flow `n` to address `reverse(n)` until we have done the whole prefix.\n    It then increases the port number sequentially.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.mappers import ReverseByteFlowMapper\n        &gt;&gt;&gt; mapper = ReverseByteFlowMapper()\n        &gt;&gt;&gt; mapper.offset(1)\n        (129, 0)\n    \"\"\"\n\n    def flow_id(self, addr_offset: int, port_offset: int, prefix: int = 0) -&gt; int:\n        assert addr_offset &lt; 256\n        if addr_offset == 0:\n            return 255\n        if port_offset != 0:\n            return 255 + port_offset\n        return self.reverse_byte(addr_offset - 1)\n\n    def offset(self, flow_id: int, prefix: int = 0) -&gt; tuple[int, int]:\n        if flow_id &lt; 255:\n            return self.reverse_byte(flow_id) + 1, 0\n        if flow_id == 255:\n            return 0, 0\n        return 255, flow_id - 255\n\n    def reverse_byte(self, i: int) -&gt; int:\n        # https://stackoverflow.com/a/2602885\n        i = (i &amp; 0xF0) &gt;&gt; 4 | (i &amp; 0x0F) &lt;&lt; 4\n        i = (i &amp; 0xCC) &gt;&gt; 2 | (i &amp; 0x33) &lt;&lt; 2\n        i = (i &amp; 0xAA) &gt;&gt; 1 | (i &amp; 0x55) &lt;&lt; 1\n        return i\n</code></pre>"},{"location":"reference/mappers/#diamond_miner.mappers.SequentialFlowMapper","title":"<code>SequentialFlowMapper</code>","text":"<p>Maps flow 0 to address 0, flow 1 to address 1, and so on until we have done the whole prefix. It then increases the port number in the same manner.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.mappers import SequentialFlowMapper\n&gt;&gt;&gt; mapper = SequentialFlowMapper()\n&gt;&gt;&gt; mapper.offset(1)\n(1, 0)\n</code></pre> Source code in <code>diamond_miner/mappers.py</code> <pre><code>class SequentialFlowMapper:\n    \"\"\"\n    Maps flow 0 to address 0, flow 1 to address 1, and so on until we have done\n    the whole prefix. It then increases the port number in the same manner.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.mappers import SequentialFlowMapper\n        &gt;&gt;&gt; mapper = SequentialFlowMapper()\n        &gt;&gt;&gt; mapper.offset(1)\n        (1, 0)\n    \"\"\"\n\n    def __init__(self, prefix_size: int = DEFAULT_PREFIX_SIZE_V4):\n        assert prefix_size &gt; 0, \"prefix_size must be positive.\"\n        self.prefix_size = prefix_size\n\n    def flow_id(self, addr_offset: int, port_offset: int, prefix: int = 0) -&gt; int:\n        return addr_offset + port_offset\n\n    def offset(self, flow_id: int, prefix: int = 0) -&gt; tuple[int, int]:\n        if flow_id &lt; self.prefix_size:\n            return flow_id, 0\n        return self.prefix_size - 1, flow_id - self.prefix_size + 1\n</code></pre>"},{"location":"reference/queries/","title":"Database queries","text":""},{"location":"reference/queries/#diamond_miner.queries","title":"<code>diamond_miner.queries</code>","text":"<p>Wrappers around ClickHouse SQL queries.</p> <p>The queries operate on different kind of tables. Refer to the following superclasses for more information: Query, LinksQuery, PrefixesQuery, ProbesQuery, ResultsQuery.</p>"},{"location":"reference/queries/#diamond_miner.queries.Count","title":"<code>Count</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Query</code></p> <p>Count the number of rows returned by a given query.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import GetLinks, GetNodes\n&gt;&gt;&gt; Count(query=GetNodes()).execute(client, 'test_nsdi_example')[0][\"count()\"]\n7\n&gt;&gt;&gt; Count(query=GetLinks()).execute(client, 'test_nsdi_example')[0][\"count()\"]\n8\n</code></pre> Source code in <code>diamond_miner/queries/count.py</code> <pre><code>@dataclass(frozen=True)\nclass Count(Query):\n    \"\"\"\n    Count the number of rows returned by a given query.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import GetLinks, GetNodes\n        &gt;&gt;&gt; Count(query=GetNodes()).execute(client, 'test_nsdi_example')[0][\"count()\"]\n        7\n        &gt;&gt;&gt; Count(query=GetLinks()).execute(client, 'test_nsdi_example')[0][\"count()\"]\n        8\n    \"\"\"\n\n    query: Query | None = None\n    \"The query for which to count the nodes.\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        # `query` must be typed `Optional` since it appears after arguments with default values.\n        assert self.query is not None\n        return f\"SELECT count() FROM ({self.query.statement(measurement_id, subset)})\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.Count.query","title":"<code>query: Query | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The query for which to count the nodes.</p>"},{"location":"reference/queries/#diamond_miner.queries.CountLinksPerPrefix","title":"<code>CountLinksPerPrefix</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LinksQuery</code></p> <p>Count the number of (non-distinct) links per prefix.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import CountLinksPerPrefix\n&gt;&gt;&gt; rows = CountLinksPerPrefix().execute(client, 'test_nsdi_example')\n&gt;&gt;&gt; sorted((row[\"prefix\"], row[\"count\"]) for row in rows)\n[('::ffff:200.0.0.0', 58)]\n</code></pre> Source code in <code>diamond_miner/queries/count_rows.py</code> <pre><code>@dataclass(frozen=True)\nclass CountLinksPerPrefix(LinksQuery):\n    \"\"\"\n    Count the number of (non-distinct) links per prefix.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import CountLinksPerPrefix\n        &gt;&gt;&gt; rows = CountLinksPerPrefix().execute(client, 'test_nsdi_example')\n        &gt;&gt;&gt; sorted((row[\"prefix\"], row[\"count\"]) for row in rows)\n        [('::ffff:200.0.0.0', 58)]\n    \"\"\"\n\n    prefix_len_v4: int = 16\n    \"The IPv4 prefix length to consider.\"\n\n    prefix_len_v6: int = 8\n    \"The IPv6 prefix length to consider.\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        return f\"\"\"\n        WITH {cut_ipv6('probe_dst_addr', self.prefix_len_v4, self.prefix_len_v6)} AS prefix\n        SELECT prefix, count() AS count\n        FROM {links_table(measurement_id)}\n        WHERE {self.filters(subset)}\n        GROUP BY prefix\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.CountLinksPerPrefix.prefix_len_v4","title":"<code>prefix_len_v4: int = 16</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The IPv4 prefix length to consider.</p>"},{"location":"reference/queries/#diamond_miner.queries.CountLinksPerPrefix.prefix_len_v6","title":"<code>prefix_len_v6: int = 8</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The IPv6 prefix length to consider.</p>"},{"location":"reference/queries/#diamond_miner.queries.CountProbesPerPrefix","title":"<code>CountProbesPerPrefix</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ProbesQuery</code></p> <p>Count the number of probes sent per prefix.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import CountProbesPerPrefix\n&gt;&gt;&gt; rows = CountResultsPerPrefix(round_eq=1).execute(client, 'test_nsdi_example')\n&gt;&gt;&gt; sorted((row[\"prefix\"], row[\"count\"]) for row in rows)\n[('::ffff:200.0.0.0', 24)]\n</code></pre> Source code in <code>diamond_miner/queries/count_rows.py</code> <pre><code>@dataclass(frozen=True)\nclass CountProbesPerPrefix(ProbesQuery):\n    \"\"\"\n    Count the number of probes sent per prefix.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import CountProbesPerPrefix\n        &gt;&gt;&gt; rows = CountResultsPerPrefix(round_eq=1).execute(client, 'test_nsdi_example')\n        &gt;&gt;&gt; sorted((row[\"prefix\"], row[\"count\"]) for row in rows)\n        [('::ffff:200.0.0.0', 24)]\n    \"\"\"\n\n    prefix_len_v4: int = 16\n    \"The IPv4 prefix length to consider.\"\n\n    prefix_len_v6: int = 8\n    \"The IPv6 prefix length to consider.\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        assert self.round_eq\n        return f\"\"\"\n        WITH {cut_ipv6('probe_dst_prefix', self.prefix_len_v4, self.prefix_len_v6)} AS prefix\n        SELECT prefix, sum(cumulative_probes) AS count\n        FROM {probes_table(measurement_id)}\n        WHERE {self.filters(subset)}\n        GROUP BY prefix\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.CountProbesPerPrefix.prefix_len_v4","title":"<code>prefix_len_v4: int = 16</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The IPv4 prefix length to consider.</p>"},{"location":"reference/queries/#diamond_miner.queries.CountProbesPerPrefix.prefix_len_v6","title":"<code>prefix_len_v6: int = 8</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The IPv6 prefix length to consider.</p>"},{"location":"reference/queries/#diamond_miner.queries.CountResultsPerPrefix","title":"<code>CountResultsPerPrefix</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultsQuery</code></p> <p>Count the number of results per prefix.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import CountResultsPerPrefix\n&gt;&gt;&gt; rows = CountResultsPerPrefix(prefix_len_v4=8, prefix_len_v6=8).execute(client, 'test_count_replies')\n&gt;&gt;&gt; sorted((row[\"prefix\"], row[\"count\"]) for row in rows)\n[('::ffff:1.0.0.0', 2), ('::ffff:2.0.0.0', 1), ('::ffff:204.0.0.0', 1)]\n</code></pre> Source code in <code>diamond_miner/queries/count_rows.py</code> <pre><code>@dataclass(frozen=True)\nclass CountResultsPerPrefix(ResultsQuery):\n    \"\"\"\n    Count the number of results per prefix.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import CountResultsPerPrefix\n        &gt;&gt;&gt; rows = CountResultsPerPrefix(prefix_len_v4=8, prefix_len_v6=8).execute(client, 'test_count_replies')\n        &gt;&gt;&gt; sorted((row[\"prefix\"], row[\"count\"]) for row in rows)\n        [('::ffff:1.0.0.0', 2), ('::ffff:2.0.0.0', 1), ('::ffff:204.0.0.0', 1)]\n    \"\"\"\n\n    prefix_len_v4: int = 16\n    \"The IPv4 prefix length to consider.\"\n\n    prefix_len_v6: int = 8\n    \"The IPv6 prefix length to consider.\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        return f\"\"\"\n        WITH {cut_ipv6('probe_dst_addr', self.prefix_len_v4, self.prefix_len_v6)} AS prefix\n        SELECT prefix, count() AS count\n        FROM {results_table(measurement_id)}\n        WHERE {self.filters(subset)}\n        GROUP BY prefix\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.CountResultsPerPrefix.prefix_len_v4","title":"<code>prefix_len_v4: int = 16</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The IPv4 prefix length to consider.</p>"},{"location":"reference/queries/#diamond_miner.queries.CountResultsPerPrefix.prefix_len_v6","title":"<code>prefix_len_v6: int = 8</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The IPv6 prefix length to consider.</p>"},{"location":"reference/queries/#diamond_miner.queries.CreateLinksTable","title":"<code>CreateLinksTable</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Query</code></p> <p>Create the links table containing one line per (flow, link) pair.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import CreateLinksTable\n&gt;&gt;&gt; CreateLinksTable().execute(client, \"test\")\n[]\n</code></pre> Source code in <code>diamond_miner/queries/create_links_table.py</code> <pre><code>@dataclass(frozen=True)\nclass CreateLinksTable(Query):\n    \"\"\"\n    Create the links table containing one line per (flow, link) pair.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import CreateLinksTable\n        &gt;&gt;&gt; CreateLinksTable().execute(client, \"test\")\n        []\n    \"\"\"\n\n    storage_policy: StoragePolicy = StoragePolicy()\n    \"ClickHouse storage policy to use.\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        assert subset == UNIVERSE_SUBSET, \"subset not allowed for this query\"\n        return f\"\"\"\n        CREATE TABLE IF NOT EXISTS {links_table(measurement_id)}\n        (\n            probe_protocol    UInt8,\n            probe_src_addr    IPv6,\n            probe_dst_prefix  IPv6,\n            probe_dst_addr    IPv6,\n            probe_src_port    UInt16,\n            probe_dst_port    UInt16,\n            near_round        UInt8,\n            far_round         UInt8,\n            near_ttl          UInt8,\n            far_ttl           UInt8,\n            near_addr         IPv6,\n            far_addr          IPv6,\n            -- Materialized columns\n            is_destination    UInt8 MATERIALIZED (near_addr = probe_dst_addr) OR (far_addr = probe_dst_addr),\n            is_inter_round    UInt8 MATERIALIZED near_round != far_round,\n            is_partial        UInt8 MATERIALIZED near_addr = toIPv6('::') OR far_addr = toIPv6('::'),\n            is_virtual        UInt8 MATERIALIZED near_addr = toIPv6('::') AND far_addr = toIPv6('::')\n        )\n        ENGINE MergeTree\n        ORDER BY (\n            probe_protocol,\n            probe_src_addr,\n            probe_dst_prefix,\n            probe_dst_addr,\n            probe_src_port,\n            probe_dst_port\n        )\n        TTL {date_time(self.storage_policy.archive_on)} TO VOLUME '{self.storage_policy.archive_to}'\n        SETTINGS storage_policy = '{self.storage_policy.name}'\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.CreateLinksTable.storage_policy","title":"<code>storage_policy: StoragePolicy = StoragePolicy()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ClickHouse storage policy to use.</p>"},{"location":"reference/queries/#diamond_miner.queries.CreatePrefixesTable","title":"<code>CreatePrefixesTable</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Query</code></p> <p>Create the table containing (invalid) prefixes.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import CreatePrefixesTable\n&gt;&gt;&gt; CreatePrefixesTable().execute(client, \"test\")\n[]\n</code></pre> Source code in <code>diamond_miner/queries/create_prefixes_table.py</code> <pre><code>@dataclass(frozen=True)\nclass CreatePrefixesTable(Query):\n    \"\"\"\n    Create the table containing (invalid) prefixes.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import CreatePrefixesTable\n        &gt;&gt;&gt; CreatePrefixesTable().execute(client, \"test\")\n        []\n    \"\"\"\n\n    SORTING_KEY = \"probe_protocol, probe_src_addr, probe_dst_prefix\"\n    \"Columns by which the data is ordered.\"\n\n    storage_policy: StoragePolicy = StoragePolicy()\n    \"ClickHouse storage policy to use.\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        return f\"\"\"\n        CREATE TABLE IF NOT EXISTS {prefixes_table(measurement_id)}\n        (\n            probe_protocol         UInt8,\n            probe_src_addr         IPv6,\n            probe_dst_prefix       IPv6,\n            has_amplification      UInt8,\n            has_loops              UInt8\n        )\n        ENGINE MergeTree\n        ORDER BY ({self.SORTING_KEY})\n        TTL {date_time(self.storage_policy.archive_on)} TO VOLUME '{self.storage_policy.archive_to}'\n        SETTINGS storage_policy = '{self.storage_policy.name}'\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.CreatePrefixesTable.SORTING_KEY","title":"<code>SORTING_KEY = 'probe_protocol, probe_src_addr, probe_dst_prefix'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Columns by which the data is ordered.</p>"},{"location":"reference/queries/#diamond_miner.queries.CreatePrefixesTable.storage_policy","title":"<code>storage_policy: StoragePolicy = StoragePolicy()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ClickHouse storage policy to use.</p>"},{"location":"reference/queries/#diamond_miner.queries.CreateProbesTable","title":"<code>CreateProbesTable</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Query</code></p> <p>Create the table containing the cumulative number of probes sent over the rounds.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import CreateProbesTable\n&gt;&gt;&gt; CreateProbesTable().execute(client, \"test\")\n[]\n</code></pre> Source code in <code>diamond_miner/queries/create_probes_table.py</code> <pre><code>@dataclass(frozen=True)\nclass CreateProbesTable(Query):\n    \"\"\"\n    Create the table containing the cumulative number of probes sent over the rounds.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import CreateProbesTable\n        &gt;&gt;&gt; CreateProbesTable().execute(client, \"test\")\n        []\n    \"\"\"\n\n    SORTING_KEY = \"probe_protocol, probe_dst_prefix, probe_ttl\"\n    \"Columns by which the data is ordered.\"\n\n    storage_policy: StoragePolicy = StoragePolicy()\n    \"ClickHouse storage policy to use.\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        return f\"\"\"\n        CREATE TABLE IF NOT EXISTS {probes_table(measurement_id)}\n        (\n            probe_protocol         UInt8,\n            probe_dst_prefix       IPv6,\n            probe_ttl              UInt8,\n            cumulative_probes      UInt32,\n            round                  UInt8\n        )\n        ENGINE MergeTree\n        ORDER BY ({self.SORTING_KEY})\n        TTL {date_time(self.storage_policy.archive_on)} TO VOLUME '{self.storage_policy.archive_to}'\n        SETTINGS storage_policy = '{self.storage_policy.name}'\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.CreateProbesTable.SORTING_KEY","title":"<code>SORTING_KEY = 'probe_protocol, probe_dst_prefix, probe_ttl'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Columns by which the data is ordered.</p>"},{"location":"reference/queries/#diamond_miner.queries.CreateProbesTable.storage_policy","title":"<code>storage_policy: StoragePolicy = StoragePolicy()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ClickHouse storage policy to use.</p>"},{"location":"reference/queries/#diamond_miner.queries.CreateResultsTable","title":"<code>CreateResultsTable</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Query</code></p> <p>Create the table used to store the measurement results from the prober.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import CreateResultsTable\n&gt;&gt;&gt; CreateResultsTable().execute(client, \"test\")\n[]\n</code></pre> Source code in <code>diamond_miner/queries/create_results_table.py</code> <pre><code>@dataclass(frozen=True)\nclass CreateResultsTable(Query):\n    \"\"\"\n    Create the table used to store the measurement results from the prober.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import CreateResultsTable\n        &gt;&gt;&gt; CreateResultsTable().execute(client, \"test\")\n        []\n    \"\"\"\n\n    SORTING_KEY = \"probe_protocol, probe_src_addr, probe_dst_prefix, probe_dst_addr, probe_src_port, probe_dst_port, probe_ttl\"\n    \"Columns by which the data is ordered.\"\n\n    prefix_len_v4: int = DEFAULT_PREFIX_LEN_V4\n    \"The prefix length used to compute the IPv4 prefix of an IP address.\"\n\n    prefix_len_v6: int = DEFAULT_PREFIX_LEN_V6\n    \"The prefix length used to compute the IPv6 prefix of an IP address.\"\n\n    storage_policy: StoragePolicy = StoragePolicy()\n    \"ClickHouse storage policy to use.\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        return f\"\"\"\n        CREATE TABLE IF NOT EXISTS {results_table(measurement_id)}\n        (\n            -- Since we do not order by capture timestamp, this column compresses badly.\n            -- To reduce its size, caracal outputs the timestamp with a one-second resolution (instead of one microsecond).\n            -- This is sufficient to know if two replies were received close in time\n            -- and avoid the inference of false links over many hours.\n            capture_timestamp      DateTime CODEC(T64, ZSTD(1)),\n            probe_protocol         UInt8,\n            probe_src_addr         IPv6,\n            probe_dst_addr         IPv6,\n            probe_src_port         UInt16,\n            probe_dst_port         UInt16,\n            probe_ttl              UInt8,\n            quoted_ttl             UInt8,\n            reply_src_addr         IPv6,\n            reply_protocol         UInt8,\n            reply_icmp_type        UInt8,\n            reply_icmp_code        UInt8,\n            reply_ttl              UInt8,\n            reply_size             UInt16,\n            reply_mpls_labels      Array(Tuple(UInt32, UInt8, UInt8, UInt8)),\n            -- The rtt column is the largest compressed column, we use T64 and ZSTD to reduce its size, see:\n            -- https://altinity.com/blog/2019/7/new-encodings-to-improve-clickhouse\n            -- https://clickhouse.tech/docs/en/sql-reference/statements/create/table/#codecs\n            rtt                    UInt16 CODEC(T64, ZSTD(1)),\n            round                  UInt8,\n            -- Materialized columns\n            probe_dst_prefix       IPv6 MATERIALIZED {cut_ipv6('probe_dst_addr', self.prefix_len_v4, self.prefix_len_v6)},\n            reply_src_prefix       IPv6 MATERIALIZED {cut_ipv6('reply_src_addr', self.prefix_len_v4, self.prefix_len_v6)},\n            -- https://en.wikipedia.org/wiki/Reserved_IP_addresses\n            private_probe_dst_prefix UInt8 MATERIALIZED\n                (probe_dst_prefix &gt;= toIPv6('0.0.0.0')      AND probe_dst_prefix &lt;= toIPv6('0.255.255.255'))   OR\n                (probe_dst_prefix &gt;= toIPv6('10.0.0.0')     AND probe_dst_prefix &lt;= toIPv6('10.255.255.255'))  OR\n                (probe_dst_prefix &gt;= toIPv6('100.64.0.0')   AND probe_dst_prefix &lt;= toIPv6('100.127.255.255')) OR\n                (probe_dst_prefix &gt;= toIPv6('127.0.0.0')    AND probe_dst_prefix &lt;= toIPv6('127.255.255.255')) OR\n                (probe_dst_prefix &gt;= toIPv6('172.16.0.0')   AND probe_dst_prefix &lt;= toIPv6('172.31.255.255'))  OR\n                (probe_dst_prefix &gt;= toIPv6('192.0.0.0')    AND probe_dst_prefix &lt;= toIPv6('192.0.0.255'))     OR\n                (probe_dst_prefix &gt;= toIPv6('192.0.2.0')    AND probe_dst_prefix &lt;= toIPv6('192.0.2.255'))     OR\n                (probe_dst_prefix &gt;= toIPv6('192.88.99.0')  AND probe_dst_prefix &lt;= toIPv6('192.88.99.255'))   OR\n                (probe_dst_prefix &gt;= toIPv6('192.168.0.0')  AND probe_dst_prefix &lt;= toIPv6('192.168.255.255')) OR\n                (probe_dst_prefix &gt;= toIPv6('198.18.0.0')   AND probe_dst_prefix &lt;= toIPv6('198.19.255.255'))  OR\n                (probe_dst_prefix &gt;= toIPv6('198.51.100.0') AND probe_dst_prefix &lt;= toIPv6('198.51.100.255'))  OR\n                (probe_dst_prefix &gt;= toIPv6('203.0.113.0')  AND probe_dst_prefix &lt;= toIPv6('203.0.113.255'))   OR\n                (probe_dst_prefix &gt;= toIPv6('224.0.0.0')    AND probe_dst_prefix &lt;= toIPv6('239.255.255.255')) OR\n                (probe_dst_prefix &gt;= toIPv6('233.252.0.0')  AND probe_dst_prefix &lt;= toIPv6('233.252.0.255'))   OR\n                (probe_dst_prefix &gt;= toIPv6('240.0.0.0')    AND probe_dst_prefix &lt;= toIPv6('255.255.255.255')) OR\n                (probe_dst_prefix &gt;= toIPv6('fd00::')       AND probe_dst_prefix &lt;= toIPv6('fdff:ffff:ffff:ffff:ffff:ffff:ffff:ffff')),\n            private_reply_src_addr UInt8 MATERIALIZED\n                (reply_src_addr &gt;= toIPv6('0.0.0.0')        AND reply_src_addr &lt;= toIPv6('0.255.255.255'))     OR\n                (reply_src_addr &gt;= toIPv6('10.0.0.0')       AND reply_src_addr &lt;= toIPv6('10.255.255.255'))    OR\n                (reply_src_addr &gt;= toIPv6('100.64.0.0')     AND reply_src_addr &lt;= toIPv6('100.127.255.255'))   OR\n                (reply_src_addr &gt;= toIPv6('127.0.0.0')      AND reply_src_addr &lt;= toIPv6('127.255.255.255'))   OR\n                (reply_src_addr &gt;= toIPv6('172.16.0.0')     AND reply_src_addr &lt;= toIPv6('172.31.255.255'))    OR\n                (reply_src_addr &gt;= toIPv6('192.0.0.0')      AND reply_src_addr &lt;= toIPv6('192.0.0.255'))       OR\n                (reply_src_addr &gt;= toIPv6('192.0.2.0')      AND reply_src_addr &lt;= toIPv6('192.0.2.255'))       OR\n                (reply_src_addr &gt;= toIPv6('192.88.99.0')    AND reply_src_addr &lt;= toIPv6('192.88.99.255'))     OR\n                (reply_src_addr &gt;= toIPv6('192.168.0.0')    AND reply_src_addr &lt;= toIPv6('192.168.255.255'))   OR\n                (reply_src_addr &gt;= toIPv6('198.18.0.0')     AND reply_src_addr &lt;= toIPv6('198.19.255.255'))    OR\n                (reply_src_addr &gt;= toIPv6('198.51.100.0')   AND reply_src_addr &lt;= toIPv6('198.51.100.255'))    OR\n                (reply_src_addr &gt;= toIPv6('203.0.113.0')    AND reply_src_addr &lt;= toIPv6('203.0.113.255'))     OR\n                (reply_src_addr &gt;= toIPv6('224.0.0.0')      AND reply_src_addr &lt;= toIPv6('239.255.255.255'))   OR\n                (reply_src_addr &gt;= toIPv6('233.252.0.0')    AND reply_src_addr &lt;= toIPv6('233.252.0.255'))     OR\n                (reply_src_addr &gt;= toIPv6('240.0.0.0')      AND reply_src_addr &lt;= toIPv6('255.255.255.255'))   OR\n                (reply_src_addr &gt;= toIPv6('fd00::')         AND reply_src_addr &lt;= toIPv6('fdff:ffff:ffff:ffff:ffff:ffff:ffff:ffff')),\n            destination_host_reply   UInt8 MATERIALIZED probe_dst_addr = reply_src_addr,\n            destination_prefix_reply UInt8 MATERIALIZED probe_dst_prefix = reply_src_prefix,\n            -- ICMP: protocol 1, UDP: protocol 17, ICMPv6: protocol 58\n            valid_probe_protocol   UInt8 MATERIALIZED probe_protocol IN [1, 17, 58],\n            time_exceeded_reply    UInt8 MATERIALIZED (reply_protocol = 1 AND reply_icmp_type = 11) OR (reply_protocol = 58 AND reply_icmp_type = 3)\n        )\n        ENGINE MergeTree\n        ORDER BY ({self.SORTING_KEY})\n        TTL {date_time(self.storage_policy.archive_on)} TO VOLUME '{self.storage_policy.archive_to}'\n        SETTINGS storage_policy = '{self.storage_policy.name}'\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.CreateResultsTable.SORTING_KEY","title":"<code>SORTING_KEY = 'probe_protocol, probe_src_addr, probe_dst_prefix, probe_dst_addr, probe_src_port, probe_dst_port, probe_ttl'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Columns by which the data is ordered.</p>"},{"location":"reference/queries/#diamond_miner.queries.CreateResultsTable.prefix_len_v4","title":"<code>prefix_len_v4: int = DEFAULT_PREFIX_LEN_V4</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The prefix length used to compute the IPv4 prefix of an IP address.</p>"},{"location":"reference/queries/#diamond_miner.queries.CreateResultsTable.prefix_len_v6","title":"<code>prefix_len_v6: int = DEFAULT_PREFIX_LEN_V6</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The prefix length used to compute the IPv6 prefix of an IP address.</p>"},{"location":"reference/queries/#diamond_miner.queries.CreateResultsTable.storage_policy","title":"<code>storage_policy: StoragePolicy = StoragePolicy()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ClickHouse storage policy to use.</p>"},{"location":"reference/queries/#diamond_miner.queries.CreateTables","title":"<code>CreateTables</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Query</code></p> <p>Create the tables necessary for a measurement.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import CreateTables\n&gt;&gt;&gt; CreateTables().execute(client, \"test\")\n[]\n</code></pre> Source code in <code>diamond_miner/queries/create_tables.py</code> <pre><code>@dataclass(frozen=True)\nclass CreateTables(Query):\n    \"\"\"\n    Create the tables necessary for a measurement.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import CreateTables\n        &gt;&gt;&gt; CreateTables().execute(client, \"test\")\n        []\n    \"\"\"\n\n    prefix_len_v4: int = DEFAULT_PREFIX_LEN_V4\n    \"The prefix length used to compute the IPv4 prefix of an IP address.\"\n\n    prefix_len_v6: int = DEFAULT_PREFIX_LEN_V6\n    \"The prefix length used to compute the IPv6 prefix of an IP address.\"\n\n    storage_policy: StoragePolicy = StoragePolicy()\n    \"ClickHouse storage policy to use.\"\n\n    def statements(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; Sequence[str]:\n        all_params = {field.name: getattr(self, field.name) for field in fields(self)}\n        # Only CreateResultsTable accepts these parameters.\n        params = {\n            x: y\n            for x, y in all_params.items()\n            if x not in [\"prefix_len_v4\", \"prefix_len_v6\"]\n        }\n        return (\n            *CreateResultsTable(**all_params).statements(measurement_id, subset),\n            *CreateLinksTable(**params).statements(measurement_id, subset),\n            *CreatePrefixesTable(**params).statements(measurement_id, subset),\n            *CreateProbesTable(**params).statements(measurement_id, subset),\n        )\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.CreateTables.prefix_len_v4","title":"<code>prefix_len_v4: int = DEFAULT_PREFIX_LEN_V4</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The prefix length used to compute the IPv4 prefix of an IP address.</p>"},{"location":"reference/queries/#diamond_miner.queries.CreateTables.prefix_len_v6","title":"<code>prefix_len_v6: int = DEFAULT_PREFIX_LEN_V6</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The prefix length used to compute the IPv6 prefix of an IP address.</p>"},{"location":"reference/queries/#diamond_miner.queries.CreateTables.storage_policy","title":"<code>storage_policy: StoragePolicy = StoragePolicy()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ClickHouse storage policy to use.</p>"},{"location":"reference/queries/#diamond_miner.queries.DropTables","title":"<code>DropTables</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Query</code></p> <p>Drop the tables associated to a measurement.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import DropTables\n&gt;&gt;&gt; DropTables().execute(client, \"test\")\n[]\n</code></pre> Source code in <code>diamond_miner/queries/drop_tables.py</code> <pre><code>@dataclass(frozen=True)\nclass DropTables(Query):\n    \"\"\"\n    Drop the tables associated to a measurement.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import DropTables\n        &gt;&gt;&gt; DropTables().execute(client, \"test\")\n        []\n    \"\"\"\n\n    def statements(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; Sequence[str]:\n        return (\n            f\"DROP TABLE IF EXISTS {results_table(measurement_id)}\",\n            f\"DROP TABLE IF EXISTS {links_table(measurement_id)}\",\n            f\"DROP TABLE IF EXISTS {prefixes_table(measurement_id)}\",\n            f\"DROP TABLE IF EXISTS {probes_table(measurement_id)}\",\n        )\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.GetInvalidPrefixes","title":"<code>GetInvalidPrefixes</code>  <code>dataclass</code>","text":"<p>               Bases: <code>PrefixesQuery</code></p> <p>Return the prefixes with unexpected behavior (see <code>GetPrefixesWithAmplification</code> and <code>GetPrefixesWithLoops</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import GetInvalidPrefixes\n&gt;&gt;&gt; rows = GetInvalidPrefixes().execute(client, \"test_invalid_prefixes\")\n&gt;&gt;&gt; [x[\"probe_dst_prefix\"] for x in rows]\n['::ffff:201.0.0.0', '::ffff:202.0.0.0']\n</code></pre> Source code in <code>diamond_miner/queries/get_invalid_prefixes.py</code> <pre><code>@dataclass(frozen=True)\nclass GetInvalidPrefixes(PrefixesQuery):\n    \"\"\"\n    Return the prefixes with unexpected behavior\n    (see `GetPrefixesWithAmplification` and `GetPrefixesWithLoops`.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import GetInvalidPrefixes\n        &gt;&gt;&gt; rows = GetInvalidPrefixes().execute(client, \"test_invalid_prefixes\")\n        &gt;&gt;&gt; [x[\"probe_dst_prefix\"] for x in rows]\n        ['::ffff:201.0.0.0', '::ffff:202.0.0.0']\n    \"\"\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        return f\"\"\"\n        SELECT probe_dst_prefix\n        FROM {prefixes_table(measurement_id)}\n        WHERE {self.filters(subset)} AND (has_amplification OR has_loops)\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.GetLinks","title":"<code>GetLinks</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LinksQuery</code></p> <p>Return the links pre-computed in the links table.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import GetLinks\n&gt;&gt;&gt; links = GetLinks(filter_invalid_prefixes=False).execute(client, 'test_invalid_prefixes')\n&gt;&gt;&gt; len(links)\n3\n&gt;&gt;&gt; links = GetLinks(filter_invalid_prefixes=True).execute(client, 'test_invalid_prefixes')\n&gt;&gt;&gt; len(links)\n1\n&gt;&gt;&gt; links = GetLinks(include_metadata=False).execute(client, 'test_nsdi_example')\n&gt;&gt;&gt; len(links)\n8\n&gt;&gt;&gt; links = GetLinks(include_metadata=True).execute(client, 'test_nsdi_example')\n&gt;&gt;&gt; len(links)\n8\n&gt;&gt;&gt; links = GetLinks(near_or_far_addr=\"150.0.6.1\").execute(client, 'test_nsdi_example')\n&gt;&gt;&gt; len(links)\n3\n</code></pre> Source code in <code>diamond_miner/queries/get_links.py</code> <pre><code>@dataclass(frozen=True)\nclass GetLinks(LinksQuery):\n    \"\"\"\n    Return the links pre-computed in the links table.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import GetLinks\n        &gt;&gt;&gt; links = GetLinks(filter_invalid_prefixes=False).execute(client, 'test_invalid_prefixes')\n        &gt;&gt;&gt; len(links)\n        3\n        &gt;&gt;&gt; links = GetLinks(filter_invalid_prefixes=True).execute(client, 'test_invalid_prefixes')\n        &gt;&gt;&gt; len(links)\n        1\n        &gt;&gt;&gt; links = GetLinks(include_metadata=False).execute(client, 'test_nsdi_example')\n        &gt;&gt;&gt; len(links)\n        8\n        &gt;&gt;&gt; links = GetLinks(include_metadata=True).execute(client, 'test_nsdi_example')\n        &gt;&gt;&gt; len(links)\n        8\n        &gt;&gt;&gt; links = GetLinks(near_or_far_addr=\"150.0.6.1\").execute(client, 'test_nsdi_example')\n        &gt;&gt;&gt; len(links)\n        3\n    \"\"\"\n\n    filter_invalid_prefixes: bool = False\n    \"If true, exclude links from prefixes with amplification or loops.\"\n\n    include_metadata: bool = False\n    \"If true, include the TTLs at which `near_addr` and `far_addr` were seen.\"\n\n    def columns(self) -&gt; list[str]:\n        columns = [\"near_addr\", \"far_addr\"]\n        if self.include_metadata:\n            columns = [\"near_ttl\", \"far_ttl\", *columns]\n        return columns\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        if self.filter_invalid_prefixes:\n            invalid_prefixes_query = GetInvalidPrefixes(\n                **common_parameters(self, GetInvalidPrefixes)\n            )\n            prefix_filter = f\"\"\"\n            probe_dst_prefix NOT IN ({invalid_prefixes_query.statement(measurement_id, subset)})\n            \"\"\"\n        else:\n            prefix_filter = \"1\"\n        return f\"\"\"\n        SELECT DISTINCT {','.join(self.columns())}\n        FROM {links_table(measurement_id)}\n        WHERE {self.filters(subset)} AND {prefix_filter}\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.GetLinks.filter_invalid_prefixes","title":"<code>filter_invalid_prefixes: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, exclude links from prefixes with amplification or loops.</p>"},{"location":"reference/queries/#diamond_miner.queries.GetLinks.include_metadata","title":"<code>include_metadata: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, include the TTLs at which <code>near_addr</code> and <code>far_addr</code> were seen.</p>"},{"location":"reference/queries/#diamond_miner.queries.GetLinksFromResults","title":"<code>GetLinksFromResults</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultsQuery</code></p> <p>Compute the links from the results table. This returns one line per <code>(flow, link)</code> pair.</p> <p>We do not emit a link in the case of single reply in a traceroute. For example: <code>* * node * *</code>, does not generate a link. However, <code>* * node * * node'</code>, will generate <code>(node, *)</code> and <code>(*, node')</code>.</p> <p>We emit cross-rounds links. For example if flow N sees node A at TTL 10 at round 1 and flow N sees node B at TTL 11 at round 2, we will emit <code>(1, 10, A) - (2, 11, B)</code>.</p> <p>We assume that there exists a single (flow, ttl) pair over all rounds (TODO: assert this).</p> <p>If <code>round_eq</code> is none, compute the links per flow, across all rounds. Otherwise, compute the links per flow, for the specified round. This is useful if you want to update a <code>links</code> table round-by-round: such a table will contain only intra-round links but can be updated incrementally.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import GetLinksFromResults\n&gt;&gt;&gt; links = GetLinksFromResults().execute(client, \"test_nsdi_example\")\n&gt;&gt;&gt; len(links)\n58\n</code></pre> Source code in <code>diamond_miner/queries/get_links_from_results.py</code> <pre><code>@dataclass(frozen=True)\nclass GetLinksFromResults(ResultsQuery):\n    \"\"\"\n    Compute the links from the results table.\n    This returns one line per `(flow, link)` pair.\n\n    We do not emit a link in the case of single reply in a traceroute.\n    For example: `* * node * *`, does not generate a link.\n    However, `* * node * * node'`, will generate `(node, *)` and `(*, node')`.\n\n    We emit cross-rounds links.\n    For example if flow N sees node A at TTL 10 at round 1 and flow N sees node B at TTL 11 at round 2,\n    we will emit `(1, 10, A) - (2, 11, B)`.\n\n    We assume that there exists a single (flow, ttl) pair over all rounds (TODO: assert this).\n\n    If `round_eq` is none, compute the links per flow, across all rounds.\n    Otherwise, compute the links per flow, for the specified round.\n    This is useful if you want to update a `links` table round-by-round:\n    such a table will contain only intra-round links but can be updated incrementally.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import GetLinksFromResults\n        &gt;&gt;&gt; links = GetLinksFromResults().execute(client, \"test_nsdi_example\")\n        &gt;&gt;&gt; len(links)\n        58\n    \"\"\"\n\n    ignore_invalid_prefixes: bool = True\n    \"If true, exclude invalid prefixes from links computation.\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        if self.ignore_invalid_prefixes:\n            invalid_filter = f\"\"\"\n            AND (probe_protocol, probe_src_addr, probe_dst_prefix)\n            NOT IN (\n                SELECT probe_protocol, probe_src_addr, probe_dst_prefix\n                FROM {prefixes_table(measurement_id)}\n                WHERE {ip_in('probe_dst_prefix', subset)}\n                AND has_amplification\n            )\n            \"\"\"\n            # TODO: We currently do not drop prefixes with loops as this considerably\n            # reduces the number of discoveries. As such, we send more probe than necessary.\n            # A better way would be to detect the min/max TTL of a loop, and to ignore it\n            # in the next round query.\n        else:\n            invalid_filter = \"\"\n\n        return f\"\"\"\n        WITH\n            groupUniqArray((round, probe_ttl, reply_src_addr)) AS traceroute,\n            arrayMap(x -&gt; x.2, traceroute) AS ttls,\n            arrayMap(x -&gt; (x.1, x.3), traceroute) AS val,\n            CAST((ttls, val), 'Map(UInt8, Tuple(UInt8, IPv6))') AS map,\n            arrayMin(ttls) AS first_ttl,\n            arrayMax(ttls) AS last_ttl,\n            arrayMap(i -&gt; (toUInt8(i), toUInt8(i + 1), map[toUInt8(i)], map[toUInt8(i + 1)]), range(first_ttl, last_ttl)) AS links,\n            arrayJoin(links) AS link\n        SELECT\n            probe_protocol,\n            probe_src_addr,\n            probe_dst_prefix,\n            probe_dst_addr,\n            probe_src_port,\n            probe_dst_port,\n            -- Set the round number for partial links:\n            -- The link (1, 10, A) -&gt; (null, 11, *) becomes\n            --          (1, 10, A) -&gt; (1,    11, *)\n            if(link.3.1 != 0, link.3.1, link.4.1) AS near_round,\n            if(link.4.1 != 0, link.4.1, link.3.1) AS far_round,\n            link.1 AS near_ttl,\n            link.2 AS far_ttl,\n            link.3.2 AS near_addr,\n            link.4.2 AS far_addr\n        FROM {results_table(measurement_id)}\n        WHERE {self.filters(subset)}\n        {invalid_filter}\n        GROUP BY (\n            probe_protocol,\n            probe_src_addr,\n            probe_dst_prefix,\n            probe_dst_addr,\n            probe_src_port,\n            probe_dst_port\n        )\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.GetLinksFromResults.ignore_invalid_prefixes","title":"<code>ignore_invalid_prefixes: bool = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, exclude invalid prefixes from links computation.</p>"},{"location":"reference/queries/#diamond_miner.queries.GetMDAProbes","title":"<code>GetMDAProbes</code>  <code>dataclass</code>","text":"<p>               Bases: <code>LinksQuery</code></p> <p>Return the number of probes to send per prefix and per TTL according to the Diamond-Miner algorithm.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import GetMDAProbes\n&gt;&gt;&gt; GetMDAProbes(round_leq=1).execute(client, \"test_nsdi_lite\")\n[{'probe_protocol': 1, 'probe_dst_prefix': '::ffff:200.0.0.0', 'cumulative_probes': [12, 12, 12, 12], 'TTLs': [1, 2, 3, 4]}]\n</code></pre> Source code in <code>diamond_miner/queries/get_mda_probes.py</code> <pre><code>@dataclass(frozen=True)\nclass GetMDAProbes(LinksQuery):\n    \"\"\"\n    Return the number of probes to send per prefix and per TTL according to the Diamond-Miner algorithm.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import GetMDAProbes\n        &gt;&gt;&gt; GetMDAProbes(round_leq=1).execute(client, \"test_nsdi_lite\")\n        [{'probe_protocol': 1, 'probe_dst_prefix': '::ffff:200.0.0.0', 'cumulative_probes': [12, 12, 12, 12], 'TTLs': [1, 2, 3, 4]}]\n    \"\"\"\n\n    adaptive_eps: bool = True\n\n    dminer_lite: bool = True\n    \"If true, use an heuristic that requires less probes to handle nested load-balancers.\"\n\n    target_epsilon: float = DEFAULT_FAILURE_RATE\n    \"\"\"\n    The desired failure rate of the MDA algorithm, that is, the probability of not detecting\n    all the outgoing edges of a load-balancer for a given prefix and TTL.\n    \"\"\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        if self.adaptive_eps:\n            eps_fragment = \"\"\"\n            arrayMax(links_per_ttl) AS max_links,\n            if(max_links == 0, target_epsilon, 1 - exp(log(1 - target_epsilon) / max_links))\n                AS epsilon,\n            \"\"\"\n        else:\n            eps_fragment = \"\"\"\n            target_epsilon AS epsilon,\n            \"\"\"\n\n        if self.dminer_lite:\n            dm_fragment = \"\"\"\n            arrayMap(k -&gt; toUInt32(ceil(ln(epsilon / (k + 1)) / ln((k + 1 - 1) / (k + 1)))), links_per_ttl) AS mda_flows,\n            \"\"\"\n        else:\n            # TODO: Implement by computing Dh(v)\n            raise NotImplementedError\n\n        return f\"\"\"\n        WITH\n            {self.target_epsilon} AS target_epsilon,\n            -- 1) Compute the links\n            --  x.1       x.2        x.3\n            -- (near_ttl, near_addr, far_addr)\n            groupUniqArray((near_ttl, near_addr, far_addr)) AS links,\n            -- 2) Count the number of links per TTL\n            -- extract only the TTLs, this greatly speeds-up arrayCount\n            arrayMap(x -&gt; x.1, links) AS links_ttls,\n            -- find the min/max TTLs\n            -- we add +2 since range() is exclusive and that we compute the max over the *near* TTL\n            range(arrayMin(links_ttls), arrayMax(links_ttls) + 2) AS TTLs,\n            -- count distinct links per TTL\n            arrayMap(t -&gt; countEqual(links_ttls, t), TTLs) AS links_per_ttl,\n            -- 3) Compute MDA stopping points\n            {eps_fragment}\n            -- 4) Compute the number of probes to send during the next round\n            {dm_fragment}\n            -- compute the number of probes to send during the next round\n            -- =&gt; max of probes to send over TTL t and t-1\n            arrayMap(i -&gt; arrayMax([mda_flows[i], mda_flows[i - 1]]), arrayEnumerate(TTLs)) AS cumulative_probes\n            -- TODO: Cleanup/optimize/rewrite/... below\n            -- do not send probes to TTLs where no replies have been received\n            -- it is unlikely that we will discover more at this TTL if the first 6 flows have seen nothing\n            -- (see GetNextRoundStateless)\n        SELECT\n            probe_protocol,\n            probe_dst_prefix,\n            cumulative_probes,\n            TTLs\n        FROM {links_table(measurement_id)} AS links_table\n        WHERE {self.filters(subset)}\n        GROUP BY (probe_protocol, probe_src_addr, probe_dst_prefix)\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.GetMDAProbes.dminer_lite","title":"<code>dminer_lite: bool = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, use an heuristic that requires less probes to handle nested load-balancers.</p>"},{"location":"reference/queries/#diamond_miner.queries.GetMDAProbes.target_epsilon","title":"<code>target_epsilon: float = DEFAULT_FAILURE_RATE</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The desired failure rate of the MDA algorithm, that is, the probability of not detecting all the outgoing edges of a load-balancer for a given prefix and TTL.</p>"},{"location":"reference/queries/#diamond_miner.queries.GetNodes","title":"<code>GetNodes</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultsQuery</code></p> <p>Return all the discovered nodes.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import GetNodes\n&gt;&gt;&gt; nodes = GetNodes(include_probe_ttl=True).execute(client, 'test_nsdi_example')\n&gt;&gt;&gt; sorted((node[\"probe_ttl\"], node[\"reply_src_addr\"]) for node in nodes)\n[(1, '::ffff:150.0.1.1'), (2, '::ffff:150.0.2.1'), (2, '::ffff:150.0.3.1'), (3, '::ffff:150.0.4.1'), (3, '::ffff:150.0.5.1'), (3, '::ffff:150.0.7.1'), (4, '::ffff:150.0.6.1')]\n&gt;&gt;&gt; nodes = GetNodes(filter_invalid_prefixes=False).execute(client, 'test_invalid_prefixes')\n&gt;&gt;&gt; sorted(node[\"reply_src_addr\"] for node in nodes)\n['::ffff:150.0.0.1', '::ffff:150.0.0.2', '::ffff:150.0.1.1', '::ffff:150.0.1.2', '::ffff:150.0.2.1', '::ffff:150.0.2.2', '::ffff:150.0.2.3']\n&gt;&gt;&gt; nodes = GetNodes(filter_invalid_prefixes=True).execute(client, 'test_invalid_prefixes')\n&gt;&gt;&gt; sorted(node[\"reply_src_addr\"] for node in nodes)\n['::ffff:150.0.0.1', '::ffff:150.0.0.2', '::ffff:150.0.2.3']\n</code></pre> Source code in <code>diamond_miner/queries/get_nodes.py</code> <pre><code>@dataclass(frozen=True)\nclass GetNodes(ResultsQuery):\n    \"\"\"\n    Return all the discovered nodes.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import GetNodes\n        &gt;&gt;&gt; nodes = GetNodes(include_probe_ttl=True).execute(client, 'test_nsdi_example')\n        &gt;&gt;&gt; sorted((node[\"probe_ttl\"], node[\"reply_src_addr\"]) for node in nodes)\n        [(1, '::ffff:150.0.1.1'), (2, '::ffff:150.0.2.1'), (2, '::ffff:150.0.3.1'), (3, '::ffff:150.0.4.1'), (3, '::ffff:150.0.5.1'), (3, '::ffff:150.0.7.1'), (4, '::ffff:150.0.6.1')]\n        &gt;&gt;&gt; nodes = GetNodes(filter_invalid_prefixes=False).execute(client, 'test_invalid_prefixes')\n        &gt;&gt;&gt; sorted(node[\"reply_src_addr\"] for node in nodes)\n        ['::ffff:150.0.0.1', '::ffff:150.0.0.2', '::ffff:150.0.1.1', '::ffff:150.0.1.2', '::ffff:150.0.2.1', '::ffff:150.0.2.2', '::ffff:150.0.2.3']\n        &gt;&gt;&gt; nodes = GetNodes(filter_invalid_prefixes=True).execute(client, 'test_invalid_prefixes')\n        &gt;&gt;&gt; sorted(node[\"reply_src_addr\"] for node in nodes)\n        ['::ffff:150.0.0.1', '::ffff:150.0.0.2', '::ffff:150.0.2.3']\n    \"\"\"\n\n    filter_invalid_prefixes: bool = False\n    \"If true, exclude nodes from prefixes with amplification or loops.\"\n\n    include_probe_ttl: bool = False\n    \"If true, include the TTL at which `reply_src_addr` was seen.\"\n\n    def columns(self) -&gt; list[str]:\n        columns = [\"reply_src_addr\"]\n        if self.include_probe_ttl:\n            columns.insert(0, \"probe_ttl\")\n        return columns\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        if self.filter_invalid_prefixes:\n            invalid_prefixes_query = GetInvalidPrefixes(\n                **common_parameters(self, GetInvalidPrefixes)\n            )\n            prefix_filter = f\"\"\"\n                    probe_dst_prefix NOT IN ({invalid_prefixes_query.statement(measurement_id, subset)})\n                    \"\"\"\n        else:\n            prefix_filter = \"1\"\n        return f\"\"\"\n        SELECT DISTINCT {','.join(self.columns())}\n        FROM {results_table(measurement_id)}\n        WHERE {self.filters(subset)} AND {prefix_filter}\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.GetNodes.filter_invalid_prefixes","title":"<code>filter_invalid_prefixes: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, exclude nodes from prefixes with amplification or loops.</p>"},{"location":"reference/queries/#diamond_miner.queries.GetNodes.include_probe_ttl","title":"<code>include_probe_ttl: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, include the TTL at which <code>reply_src_addr</code> was seen.</p>"},{"location":"reference/queries/#diamond_miner.queries.GetPrefixes","title":"<code>GetPrefixes</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultsQuery</code></p> <p>Return the destination prefixes for which replies have been received.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import GetPrefixes\n&gt;&gt;&gt; from ipaddress import ip_network\n&gt;&gt;&gt; rows = GetPrefixes().execute(client, 'test_nsdi_example')\n&gt;&gt;&gt; len(rows)\n1\n&gt;&gt;&gt; rows = GetPrefixes().execute(client, 'test_invalid_prefixes')\n&gt;&gt;&gt; len(rows)\n3\n&gt;&gt;&gt; rows = GetPrefixes(reply_src_addr_in=ip_network(\"150.0.1.0/24\")).execute(client, 'test_invalid_prefixes')\n&gt;&gt;&gt; len(rows)\n1\n</code></pre> Source code in <code>diamond_miner/queries/get_prefixes.py</code> <pre><code>@dataclass(frozen=True)\nclass GetPrefixes(ResultsQuery):\n    \"\"\"\n    Return the destination prefixes for which replies have been received.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import GetPrefixes\n        &gt;&gt;&gt; from ipaddress import ip_network\n        &gt;&gt;&gt; rows = GetPrefixes().execute(client, 'test_nsdi_example')\n        &gt;&gt;&gt; len(rows)\n        1\n        &gt;&gt;&gt; rows = GetPrefixes().execute(client, 'test_invalid_prefixes')\n        &gt;&gt;&gt; len(rows)\n        3\n        &gt;&gt;&gt; rows = GetPrefixes(reply_src_addr_in=ip_network(\"150.0.1.0/24\")).execute(client, 'test_invalid_prefixes')\n        &gt;&gt;&gt; len(rows)\n        1\n    \"\"\"\n\n    reply_src_addr_in: IPNetwork | None = None\n    \"If specified, keep only the replies from this network.\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        # The prefixes table doesn't contains network information, so we\n        # need to join the results table for these filters.\n        join_fragment = \"\"\n        if self.reply_src_addr_in:\n            join_fragment = f\"\"\"\n            INNER JOIN (\n                SELECT DISTINCT probe_protocol, probe_src_addr, probe_dst_prefix\n                FROM {results_table(measurement_id)}\n                WHERE {self.filters(subset)} AND {ip_in('reply_src_addr', self.reply_src_addr_in)}\n            ) AS results\n            ON  prefixes.probe_protocol   = results.probe_protocol\n            AND prefixes.probe_src_addr   = results.probe_src_addr\n            AND prefixes.probe_dst_prefix = results.probe_dst_prefix\n            \"\"\"\n        return f\"\"\"\n        SELECT probe_dst_prefix, has_amplification, has_loops\n        FROM {prefixes_table(measurement_id)} AS prefixes\n        {join_fragment}\n        ORDER BY {CreatePrefixesTable.SORTING_KEY}\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.GetPrefixes.reply_src_addr_in","title":"<code>reply_src_addr_in: IPNetwork | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the replies from this network.</p>"},{"location":"reference/queries/#diamond_miner.queries.GetPrefixesWithAmplification","title":"<code>GetPrefixesWithAmplification</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultsQuery</code></p> <p>Return the prefixes for which we have more than one reply per (flow ID, TTL).</p> Important <p>This query assumes that a single probe is sent per (flow ID, TTL) pair.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import GetPrefixesWithAmplification\n&gt;&gt;&gt; rows = GetPrefixesWithAmplification().execute(client, \"test_invalid_prefixes\")\n&gt;&gt;&gt; [x[\"probe_dst_prefix\"] for x in rows]\n['::ffff:202.0.0.0']\n</code></pre> Source code in <code>diamond_miner/queries/get_invalid_prefixes.py</code> <pre><code>@dataclass(frozen=True)\nclass GetPrefixesWithAmplification(ResultsQuery):\n    \"\"\"\n    Return the prefixes for which we have more than one reply per (flow ID, TTL).\n\n    Important:\n        This query assumes that a single probe is sent per (flow ID, TTL) pair.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import GetPrefixesWithAmplification\n        &gt;&gt;&gt; rows = GetPrefixesWithAmplification().execute(client, \"test_invalid_prefixes\")\n        &gt;&gt;&gt; [x[\"probe_dst_prefix\"] for x in rows]\n        ['::ffff:202.0.0.0']\n    \"\"\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        return f\"\"\"\n        SELECT DISTINCT\n            probe_protocol,\n            probe_src_addr,\n            probe_dst_prefix,\n            -- This column is to simplify the InsertPrefixes query.\n            1 AS has_amplification\n        FROM {results_table(measurement_id)}\n        WHERE {self.filters(subset)}\n        GROUP BY (\n            probe_protocol,\n            probe_src_addr,\n            probe_dst_prefix,\n            probe_dst_addr,\n            probe_src_port,\n            probe_dst_port,\n            probe_ttl\n        )\n        HAVING count() &gt; 1\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.GetPrefixesWithLoops","title":"<code>GetPrefixesWithLoops</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultsQuery</code></p> <p>Return the prefixes for which an IP address appears multiple time for a single flow ID.</p> Important <p>Prefixes with amplification (multiple replies per probe) may trigger a false positive for this query, since we do not check that the IP appears at two different TTLs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import GetPrefixesWithLoops\n&gt;&gt;&gt; GetPrefixesWithLoops().execute(client, \"test_invalid_prefixes\")\n[{'probe_protocol': 1, 'probe_src_addr': '::ffff:100.0.0.1', 'probe_dst_prefix': '::ffff:201.0.0.0', 'has_loops': 1}]\n</code></pre> Source code in <code>diamond_miner/queries/get_invalid_prefixes.py</code> <pre><code>@dataclass(frozen=True)\nclass GetPrefixesWithLoops(ResultsQuery):\n    \"\"\"\n    Return the prefixes for which an IP address appears multiple time for a single flow ID.\n\n    Important:\n        Prefixes with amplification (multiple replies per probe) may trigger a false positive\n        for this query, since we do not check that the IP appears at two *different* TTLs.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import GetPrefixesWithLoops\n        &gt;&gt;&gt; GetPrefixesWithLoops().execute(client, \"test_invalid_prefixes\")\n        [{'probe_protocol': 1, 'probe_src_addr': '::ffff:100.0.0.1', 'probe_dst_prefix': '::ffff:201.0.0.0', 'has_loops': 1}]\n    \"\"\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        return f\"\"\"\n        SELECT DISTINCT\n            probe_protocol,\n            probe_src_addr,\n            probe_dst_prefix,\n            -- This column is to simplify the InsertPrefixes query.\n            1 AS has_loops\n        FROM {results_table(measurement_id)}\n        WHERE {self.filters(subset)}\n        GROUP BY (\n            probe_protocol,\n            probe_src_addr,\n            probe_dst_prefix,\n            probe_dst_addr,\n            probe_src_port,\n            probe_dst_port\n        )\n        HAVING uniqExact(reply_src_addr) &lt; count()\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.GetProbes","title":"<code>GetProbes</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ProbesQuery</code></p> <p>Return the cumulative number of probes sent at a specified round.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import GetProbes\n&gt;&gt;&gt; row = GetProbes(round_eq=1).execute(client, 'test_nsdi_example')[0]\n&gt;&gt;&gt; row[\"probe_protocol\"]\n1\n&gt;&gt;&gt; row[\"probe_dst_prefix\"]\n'::ffff:200.0.0.0'\n&gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n[[1, 6], [2, 6], [3, 6], [4, 6]]\n&gt;&gt;&gt; row = GetProbes(round_eq=2).execute(client, 'test_nsdi_example')[0]\n&gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n[[1, 11], [2, 18], [3, 18], [4, 18]]\n&gt;&gt;&gt; row = GetProbes(round_eq=3).execute(client, 'test_nsdi_example')[0]\n&gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n[[1, 11], [2, 20], [3, 27], [4, 27]]\n&gt;&gt;&gt; row = GetProbes(round_eq=3, probe_ttl_geq=2, probe_ttl_leq=3).execute(client, 'test_nsdi_example')[0]\n&gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n[[2, 20], [3, 27]]\n&gt;&gt;&gt; GetProbes(round_eq=4).execute(client, 'test_nsdi_example')\n[]\n</code></pre> Source code in <code>diamond_miner/queries/get_probes.py</code> <pre><code>class GetProbes(ProbesQuery):\n    \"\"\"\n    Return the cumulative number of probes sent at a specified round.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import GetProbes\n        &gt;&gt;&gt; row = GetProbes(round_eq=1).execute(client, 'test_nsdi_example')[0]\n        &gt;&gt;&gt; row[\"probe_protocol\"]\n        1\n        &gt;&gt;&gt; row[\"probe_dst_prefix\"]\n        '::ffff:200.0.0.0'\n        &gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n        [[1, 6], [2, 6], [3, 6], [4, 6]]\n        &gt;&gt;&gt; row = GetProbes(round_eq=2).execute(client, 'test_nsdi_example')[0]\n        &gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n        [[1, 11], [2, 18], [3, 18], [4, 18]]\n        &gt;&gt;&gt; row = GetProbes(round_eq=3).execute(client, 'test_nsdi_example')[0]\n        &gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n        [[1, 11], [2, 20], [3, 27], [4, 27]]\n        &gt;&gt;&gt; row = GetProbes(round_eq=3, probe_ttl_geq=2, probe_ttl_leq=3).execute(client, 'test_nsdi_example')[0]\n        &gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n        [[2, 20], [3, 27]]\n        &gt;&gt;&gt; GetProbes(round_eq=4).execute(client, 'test_nsdi_example')\n        []\n    \"\"\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        assert self.round_eq, \"`round_eq` must be specified.\"\n        return f\"\"\"\n        SELECT\n            probe_protocol,\n            probe_dst_prefix,\n            groupArray((probe_ttl, cumulative_probes)) AS probes_per_ttl\n        FROM {probes_table(measurement_id)}\n        WHERE {self.filters(subset)}\n        GROUP BY (probe_protocol, probe_dst_prefix)\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.GetProbesDiff","title":"<code>GetProbesDiff</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ProbesQuery</code></p> <p>Return the number of probes sent at a specific round and at the previous round.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import GetProbesDiff\n&gt;&gt;&gt; row = GetProbesDiff(round_eq=1).execute(client, 'test_nsdi_example')[0]\n&gt;&gt;&gt; row[\"probe_protocol\"]\n1\n&gt;&gt;&gt; row[\"probe_dst_prefix\"]\n'::ffff:200.0.0.0'\n&gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n[[1, 6, 0], [2, 6, 0], [3, 6, 0], [4, 6, 0]]\n&gt;&gt;&gt; row = GetProbesDiff(round_eq=2).execute(client, 'test_nsdi_example')[0]\n&gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n[[1, 11, 6], [2, 18, 6], [3, 18, 6], [4, 18, 6]]\n&gt;&gt;&gt; row = GetProbesDiff(round_eq=3).execute(client, 'test_nsdi_example')[0]\n&gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n[[1, 11, 11], [2, 20, 18], [3, 27, 18], [4, 27, 18]]\n&gt;&gt;&gt; GetProbesDiff(round_eq=4).execute(client, 'test_nsdi_example')\n[]\n</code></pre> Source code in <code>diamond_miner/queries/get_probes.py</code> <pre><code>class GetProbesDiff(ProbesQuery):\n    \"\"\"\n    Return the number of probes sent at a specific round and at the previous round.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import GetProbesDiff\n        &gt;&gt;&gt; row = GetProbesDiff(round_eq=1).execute(client, 'test_nsdi_example')[0]\n        &gt;&gt;&gt; row[\"probe_protocol\"]\n        1\n        &gt;&gt;&gt; row[\"probe_dst_prefix\"]\n        '::ffff:200.0.0.0'\n        &gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n        [[1, 6, 0], [2, 6, 0], [3, 6, 0], [4, 6, 0]]\n        &gt;&gt;&gt; row = GetProbesDiff(round_eq=2).execute(client, 'test_nsdi_example')[0]\n        &gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n        [[1, 11, 6], [2, 18, 6], [3, 18, 6], [4, 18, 6]]\n        &gt;&gt;&gt; row = GetProbesDiff(round_eq=3).execute(client, 'test_nsdi_example')[0]\n        &gt;&gt;&gt; sorted(row[\"probes_per_ttl\"])\n        [[1, 11, 11], [2, 20, 18], [3, 27, 18], [4, 27, 18]]\n        &gt;&gt;&gt; GetProbesDiff(round_eq=4).execute(client, 'test_nsdi_example')\n        []\n    \"\"\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        assert self.round_eq\n        return f\"\"\"\n        SELECT\n            current.probe_protocol,\n            current.probe_dst_prefix,\n            groupArray((current.probe_ttl, current.cumulative_probes, previous.cumulative_probes)) AS probes_per_ttl\n        FROM {probes_table(measurement_id)} AS current\n        LEFT JOIN (\n            SELECT\n                probe_protocol,\n                probe_dst_prefix,\n                probe_ttl,\n                cumulative_probes\n            FROM {probes_table(measurement_id)}\n            WHERE {ip_in(\"probe_dst_prefix\", subset)} AND round = {self.round_eq - 1}\n        ) AS previous\n        ON current.probe_protocol = previous.probe_protocol\n        AND current.probe_dst_prefix = previous.probe_dst_prefix\n        AND current.probe_ttl = previous.probe_ttl\n        WHERE {self.filters(subset)}\n        GROUP BY (current.probe_protocol, current.probe_dst_prefix)\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.GetResults","title":"<code>GetResults</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultsQuery</code></p> <p>Return all the columns from the results table.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from diamond_miner.test import client\n&gt;&gt;&gt; from diamond_miner.queries import GetResults\n&gt;&gt;&gt; rows = GetResults().execute(client, 'test_nsdi_example')\n&gt;&gt;&gt; len(rows)\n85\n</code></pre> Source code in <code>diamond_miner/queries/get_results.py</code> <pre><code>@dataclass(frozen=True)\nclass GetResults(ResultsQuery):\n    \"\"\"\n    Return all the columns from the results table.\n\n    Examples:\n        &gt;&gt;&gt; from diamond_miner.test import client\n        &gt;&gt;&gt; from diamond_miner.queries import GetResults\n        &gt;&gt;&gt; rows = GetResults().execute(client, 'test_nsdi_example')\n        &gt;&gt;&gt; len(rows)\n        85\n    \"\"\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        return f\"\"\"\n        SELECT *\n        FROM {results_table(measurement_id)}\n        WHERE {self.filters(subset)}\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.GetSlidingPrefixes","title":"<code>GetSlidingPrefixes</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultsQuery</code></p> <p>Get the prefixes to probe for a given sliding window.</p> Source code in <code>diamond_miner/queries/get_sliding_prefixes.py</code> <pre><code>@dataclass(frozen=True)\nclass GetSlidingPrefixes(ResultsQuery):\n    \"\"\"\n    Get the prefixes to probe for a given sliding window.\n    \"\"\"\n\n    stopping_condition: int = 0\n    \"Number of stars to allow.\"\n\n    window_max_ttl: int = 0\n    \"Set to 0 to return every prefix.\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        assert self.filter_destination_host and self.time_exceeded_only\n        return f\"\"\"\n        SELECT\n            probe_protocol,\n            probe_src_addr,\n            probe_dst_prefix\n        FROM {results_table(measurement_id)}\n        WHERE {self.filters(subset)}\n        AND probe_ttl &gt;= {self.window_max_ttl - self.stopping_condition}\n        GROUP BY (\n            probe_protocol,\n            probe_src_addr,\n            probe_dst_prefix\n        )\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.GetSlidingPrefixes.stopping_condition","title":"<code>stopping_condition: int = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of stars to allow.</p>"},{"location":"reference/queries/#diamond_miner.queries.GetSlidingPrefixes.window_max_ttl","title":"<code>window_max_ttl: int = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Set to 0 to return every prefix.</p>"},{"location":"reference/queries/#diamond_miner.queries.InsertLinks","title":"<code>InsertLinks</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultsQuery</code></p> <p>Insert the results of the <code>GetLinksFromResults</code> query into the links table.</p> Source code in <code>diamond_miner/queries/insert_links.py</code> <pre><code>@dataclass(frozen=True)\nclass InsertLinks(ResultsQuery):\n    \"\"\"\n    Insert the results of the `GetLinksFromResults` query into the links table.\n    \"\"\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        links_query = GetLinksFromResults(**asdict(self)).statement(\n            measurement_id, subset\n        )\n        return f\"\"\"\n        INSERT INTO {links_table(measurement_id)}\n        SELECT * FROM ({links_query})\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.InsertMDAProbes","title":"<code>InsertMDAProbes</code>  <code>dataclass</code>","text":"<p>               Bases: <code>GetMDAProbes</code></p> <p>Insert the result of the <code>GetMDAProbes</code> queries into the probes table.</p> Source code in <code>diamond_miner/queries/insert_mda_probes.py</code> <pre><code>@dataclass(frozen=True)\nclass InsertMDAProbes(GetMDAProbes):\n    \"\"\"\n    Insert the result of the `GetMDAProbes` queries\n    into the probes table.\n    \"\"\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        assert self.round_leq\n        return f\"\"\"\n        INSERT INTO {probes_table(measurement_id)}\n        WITH\n            arrayJoin(arrayZip(TTLs, cumulative_probes)) AS ttl_probe\n        SELECT\n            probe_protocol,\n            probe_dst_prefix,\n            ttl_probe.1,\n            ttl_probe.2,\n            {self.round_leq + 1}\n        FROM ({super().statement(measurement_id, subset)})\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.InsertPrefixes","title":"<code>InsertPrefixes</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultsQuery</code></p> <p>Insert the results of the <code>GetPrefixesWithAmplification</code> and <code>GetPrefixesWithLoops</code> queries into the prefixes table.</p> Source code in <code>diamond_miner/queries/insert_prefixes.py</code> <pre><code>@dataclass(frozen=True)\nclass InsertPrefixes(ResultsQuery):\n    \"\"\"\n    Insert the results of the `GetPrefixesWithAmplification` and `GetPrefixesWithLoops` queries into the prefixes table.\n    \"\"\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        amplification_query = GetPrefixesWithAmplification(**asdict(self)).statement(\n            measurement_id, subset\n        )\n        loops_query = GetPrefixesWithLoops(**asdict(self)).statement(\n            measurement_id, subset\n        )\n        return f\"\"\"\n        INSERT INTO {prefixes_table(measurement_id)}\n        SELECT\n            prefixes.probe_protocol,\n            prefixes.probe_src_addr,\n            prefixes.probe_dst_prefix,\n            amplification.has_amplification,\n            loops.has_loops\n        FROM (\n            SELECT DISTINCT probe_protocol, probe_src_addr, probe_dst_prefix\n            FROM {results_table(measurement_id)}\n            WHERE {self.filters(subset)}\n        ) AS prefixes\n        FULL OUTER JOIN ({amplification_query}) AS amplification\n        ON  prefixes.probe_protocol   = amplification.probe_protocol\n        AND prefixes.probe_src_addr   = amplification.probe_src_addr\n        AND prefixes.probe_dst_prefix = amplification.probe_dst_prefix\n        FULL OUTER JOIN ({loops_query}) AS loops\n        ON  prefixes.probe_protocol   = loops.probe_protocol\n        AND prefixes.probe_src_addr   = loops.probe_src_addr\n        AND prefixes.probe_dst_prefix = loops.probe_dst_prefix\n        WHERE prefixes.probe_dst_prefix != toIPv6('::')\n        \"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.InsertResults","title":"<code>InsertResults</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Query</code></p> <p>Insert measurement results from a CSV file.</p> Source code in <code>diamond_miner/queries/insert_results.py</code> <pre><code>@dataclass(frozen=True)\nclass InsertResults(Query):\n    \"\"\"\n    Insert measurement results from a CSV file.\n    \"\"\"\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        return f\"INSERT INTO {results_table(measurement_id)} FORMAT CSVWithNames\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.LinksQuery","title":"<code>LinksQuery</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Query</code></p> <p>Base class for queries on the links table.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>@dataclass(frozen=True)\nclass LinksQuery(Query):\n    \"\"\"Base class for queries on the links table.\"\"\"\n\n    filter_inter_round: bool = False\n    \"If true, exclude links inferred across rounds.\"\n\n    filter_partial: bool = False\n    \"If true, exclude partial links: `('::', node)` and `(node, '::')`.\"\n\n    filter_virtual: bool = False\n    \"If true, exclude virtual links: `('::', '::')`.\"\n\n    near_or_far_addr: str | None = None\n    \"If specified, keep only the links that contains this IP address.\"\n\n    probe_protocol: int | None = None\n    \"If specified, keep only the links inferred from probes sent with this protocol.\"\n\n    probe_src_addr: str | None = None\n    \"\"\"\n    If specified, keep only the links inferred from probes sent by this address.\n    This filter is relatively costly (IPv6 comparison on each row).\n    \"\"\"\n\n    round_eq: int | None = None\n    \"If specified, keep only the links from this round.\"\n\n    round_leq: int | None = None\n    \"If specified, keep only the links from this round or before.\"\n\n    def filters(self, subset: IPNetwork) -&gt; str:\n        \"\"\"`WHERE` clause common to all queries on the links table.\"\"\"\n        s = []\n        if subset != UNIVERSE_SUBSET:\n            s += [ip_in(\"probe_dst_prefix\", subset)]\n        if self.probe_protocol:\n            s += [eq(\"probe_protocol\", self.probe_protocol)]\n        if self.probe_src_addr:\n            s += [ip_eq(\"probe_src_addr\", self.probe_src_addr)]\n        if self.round_eq:\n            s += [eq(\"near_round\", self.round_eq), eq(\"far_round\", self.round_eq)]\n        if self.round_leq:\n            s += [leq(\"near_round\", self.round_leq), leq(\"far_round\", self.round_leq)]\n        if self.near_or_far_addr:\n            s += [\n                or_(\n                    ip_eq(\"near_addr\", self.near_or_far_addr),\n                    ip_eq(\"far_addr\", self.near_or_far_addr),\n                )\n            ]\n        if self.filter_inter_round:\n            s += [not_(\"is_inter_round\")]\n        if self.filter_partial:\n            s += [not_(\"is_partial\")]\n        if self.filter_virtual:\n            s += [not_(\"is_virtual\")]\n        return reduce(and_, s or [\"1\"])\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.LinksQuery.filter_inter_round","title":"<code>filter_inter_round: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, exclude links inferred across rounds.</p>"},{"location":"reference/queries/#diamond_miner.queries.LinksQuery.filter_partial","title":"<code>filter_partial: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, exclude partial links: <code>('::', node)</code> and <code>(node, '::')</code>.</p>"},{"location":"reference/queries/#diamond_miner.queries.LinksQuery.filter_virtual","title":"<code>filter_virtual: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, exclude virtual links: <code>('::', '::')</code>.</p>"},{"location":"reference/queries/#diamond_miner.queries.LinksQuery.near_or_far_addr","title":"<code>near_or_far_addr: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the links that contains this IP address.</p>"},{"location":"reference/queries/#diamond_miner.queries.LinksQuery.probe_protocol","title":"<code>probe_protocol: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the links inferred from probes sent with this protocol.</p>"},{"location":"reference/queries/#diamond_miner.queries.LinksQuery.probe_src_addr","title":"<code>probe_src_addr: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the links inferred from probes sent by this address. This filter is relatively costly (IPv6 comparison on each row).</p>"},{"location":"reference/queries/#diamond_miner.queries.LinksQuery.round_eq","title":"<code>round_eq: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the links from this round.</p>"},{"location":"reference/queries/#diamond_miner.queries.LinksQuery.round_leq","title":"<code>round_leq: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the links from this round or before.</p>"},{"location":"reference/queries/#diamond_miner.queries.LinksQuery.filters","title":"<code>filters(subset)</code>","text":"<p><code>WHERE</code> clause common to all queries on the links table.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>def filters(self, subset: IPNetwork) -&gt; str:\n    \"\"\"`WHERE` clause common to all queries on the links table.\"\"\"\n    s = []\n    if subset != UNIVERSE_SUBSET:\n        s += [ip_in(\"probe_dst_prefix\", subset)]\n    if self.probe_protocol:\n        s += [eq(\"probe_protocol\", self.probe_protocol)]\n    if self.probe_src_addr:\n        s += [ip_eq(\"probe_src_addr\", self.probe_src_addr)]\n    if self.round_eq:\n        s += [eq(\"near_round\", self.round_eq), eq(\"far_round\", self.round_eq)]\n    if self.round_leq:\n        s += [leq(\"near_round\", self.round_leq), leq(\"far_round\", self.round_leq)]\n    if self.near_or_far_addr:\n        s += [\n            or_(\n                ip_eq(\"near_addr\", self.near_or_far_addr),\n                ip_eq(\"far_addr\", self.near_or_far_addr),\n            )\n        ]\n    if self.filter_inter_round:\n        s += [not_(\"is_inter_round\")]\n    if self.filter_partial:\n        s += [not_(\"is_partial\")]\n    if self.filter_virtual:\n        s += [not_(\"is_virtual\")]\n    return reduce(and_, s or [\"1\"])\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.PrefixesQuery","title":"<code>PrefixesQuery</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Query</code></p> <p>Base class for queries on the prefixes table.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>@dataclass(frozen=True)\nclass PrefixesQuery(Query):\n    \"\"\"Base class for queries on the prefixes table.\"\"\"\n\n    probe_protocol: int | None = None\n    \"If specified, keep only the links inferred from probes sent with this protocol.\"\n\n    probe_src_addr: str | None = None\n    \"\"\"\n    If specified, keep only the links inferred from probes sent by this address.\n    This filter is relatively costly (IPv6 comparison on each row).\n    \"\"\"\n\n    def filters(self, subset: IPNetwork) -&gt; str:\n        \"\"\"`WHERE` clause common to all queries on the prefixes table.\"\"\"\n        s = []\n        if subset != UNIVERSE_SUBSET:\n            s += [ip_in(\"probe_dst_prefix\", subset)]\n        if self.probe_protocol:\n            s += [eq(\"probe_protocol\", self.probe_protocol)]\n        if self.probe_src_addr:\n            s += [ip_eq(\"probe_src_addr\", self.probe_src_addr)]\n        return reduce(and_, s or [\"1\"])\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.PrefixesQuery.probe_protocol","title":"<code>probe_protocol: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the links inferred from probes sent with this protocol.</p>"},{"location":"reference/queries/#diamond_miner.queries.PrefixesQuery.probe_src_addr","title":"<code>probe_src_addr: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the links inferred from probes sent by this address. This filter is relatively costly (IPv6 comparison on each row).</p>"},{"location":"reference/queries/#diamond_miner.queries.PrefixesQuery.filters","title":"<code>filters(subset)</code>","text":"<p><code>WHERE</code> clause common to all queries on the prefixes table.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>def filters(self, subset: IPNetwork) -&gt; str:\n    \"\"\"`WHERE` clause common to all queries on the prefixes table.\"\"\"\n    s = []\n    if subset != UNIVERSE_SUBSET:\n        s += [ip_in(\"probe_dst_prefix\", subset)]\n    if self.probe_protocol:\n        s += [eq(\"probe_protocol\", self.probe_protocol)]\n    if self.probe_src_addr:\n        s += [ip_eq(\"probe_src_addr\", self.probe_src_addr)]\n    return reduce(and_, s or [\"1\"])\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.ProbesQuery","title":"<code>ProbesQuery</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Query</code></p> <p>Base class for queries on the probes table.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>@dataclass(frozen=True)\nclass ProbesQuery(Query):\n    \"\"\"Base class for queries on the probes table.\"\"\"\n\n    probe_protocol: int | None = None\n    \"If specified, keep only probes sent with this protocol.\"\n\n    probe_ttl_geq: int | None = None\n    \"If specified, keep only the probes with TTL &gt;= this value.\"\n\n    probe_ttl_leq: int | None = None\n    \"If specified, keep only the probes with TTL &lt;= this value.\"\n\n    round_eq: int | None = None\n    \"If specified, keep only the probes from this round.\"\n\n    round_geq: int | None = None\n    \"If specified, keep only the probes from this round or after.\"\n\n    round_leq: int | None = None\n    \"If specified, keep only the probes from this round or before.\"\n\n    round_lt: int | None = None\n    \"If specified, keep only the probes from before this round.\"\n\n    def filters(self, subset: IPNetwork) -&gt; str:\n        \"\"\"`WHERE` clause common to all queries on the probes table.\"\"\"\n        s = []\n        if subset != UNIVERSE_SUBSET:\n            s += [ip_in(\"probe_dst_prefix\", subset)]\n        if self.probe_protocol:\n            s += [eq(\"probe_protocol\", self.probe_protocol)]\n        if self.probe_ttl_geq:\n            s += [geq(\"probe_ttl\", self.probe_ttl_geq)]\n        if self.probe_ttl_leq:\n            s += [leq(\"probe_ttl\", self.probe_ttl_leq)]\n        if self.round_eq:\n            s += [eq(\"round\", self.round_eq)]\n        if self.round_geq:\n            s += [geq(\"round\", self.round_geq)]\n        if self.round_lt:\n            s += [lt(\"round\", self.round_lt)]\n        if self.round_leq:\n            s += [leq(\"round\", self.round_leq)]\n        return reduce(and_, s or [\"1\"])\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.ProbesQuery.probe_protocol","title":"<code>probe_protocol: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only probes sent with this protocol.</p>"},{"location":"reference/queries/#diamond_miner.queries.ProbesQuery.probe_ttl_geq","title":"<code>probe_ttl_geq: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the probes with TTL &gt;= this value.</p>"},{"location":"reference/queries/#diamond_miner.queries.ProbesQuery.probe_ttl_leq","title":"<code>probe_ttl_leq: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the probes with TTL &lt;= this value.</p>"},{"location":"reference/queries/#diamond_miner.queries.ProbesQuery.round_eq","title":"<code>round_eq: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the probes from this round.</p>"},{"location":"reference/queries/#diamond_miner.queries.ProbesQuery.round_geq","title":"<code>round_geq: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the probes from this round or after.</p>"},{"location":"reference/queries/#diamond_miner.queries.ProbesQuery.round_leq","title":"<code>round_leq: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the probes from this round or before.</p>"},{"location":"reference/queries/#diamond_miner.queries.ProbesQuery.round_lt","title":"<code>round_lt: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the probes from before this round.</p>"},{"location":"reference/queries/#diamond_miner.queries.ProbesQuery.filters","title":"<code>filters(subset)</code>","text":"<p><code>WHERE</code> clause common to all queries on the probes table.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>def filters(self, subset: IPNetwork) -&gt; str:\n    \"\"\"`WHERE` clause common to all queries on the probes table.\"\"\"\n    s = []\n    if subset != UNIVERSE_SUBSET:\n        s += [ip_in(\"probe_dst_prefix\", subset)]\n    if self.probe_protocol:\n        s += [eq(\"probe_protocol\", self.probe_protocol)]\n    if self.probe_ttl_geq:\n        s += [geq(\"probe_ttl\", self.probe_ttl_geq)]\n    if self.probe_ttl_leq:\n        s += [leq(\"probe_ttl\", self.probe_ttl_leq)]\n    if self.round_eq:\n        s += [eq(\"round\", self.round_eq)]\n    if self.round_geq:\n        s += [geq(\"round\", self.round_geq)]\n    if self.round_lt:\n        s += [lt(\"round\", self.round_lt)]\n    if self.round_leq:\n        s += [leq(\"round\", self.round_leq)]\n    return reduce(and_, s or [\"1\"])\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.Query","title":"<code>Query</code>  <code>dataclass</code>","text":"<p>Base class for every query.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>@dataclass(frozen=True)\nclass Query:\n    \"\"\"Base class for every query.\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        return self.__class__.__name__\n\n    def statement(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; str:\n        # As a query user, prefer calling `statements` instead of `statement` as there\n        # is no guarantees that the query will implement this method and return a single statement.\n        raise NotImplementedError\n\n    def statements(\n        self, measurement_id: str, subset: IPNetwork = UNIVERSE_SUBSET\n    ) -&gt; Sequence[str]:\n        # Override this method if you want your query to return multiple statements.\n        return (self.statement(measurement_id, subset),)\n\n    def execute(\n        self,\n        client: ClickHouseClient,\n        measurement_id: str,\n        *,\n        data: Any | None = None,\n        limit: tuple[int, int] | None = None,\n        subsets: Iterable[IPNetwork] = (UNIVERSE_SUBSET,),\n    ) -&gt; list[dict]:\n        \"\"\"\n        Execute the query and return each row as a dict.\n        Args:\n            client: ClickHouse client.\n            measurement_id: Measurement id.\n            data: str or bytes iterator containing data to send.\n            limit: (limit, offset) tuple.\n            subsets: Iterable of IP networks on which to execute the query independently.\n        \"\"\"\n        rows = []\n        for subset in subsets:\n            for i, statement in enumerate(self.statements(measurement_id, subset)):\n                with LoggingTimer(\n                    logger,\n                    f\"query={self.name}#{i} measurement_id={measurement_id} subset={subset} limit={limit}\",\n                ):\n                    settings = dict(\n                        limit=limit[0] if limit else 0,\n                        offset=limit[1] if limit else 0,\n                    )\n                    rows += client.json(statement, data=data, settings=settings)\n        return rows\n\n    def execute_iter(\n        self,\n        client: ClickHouseClient,\n        measurement_id: str,\n        *,\n        data: Any | None = None,\n        limit: tuple[int, int] | None = None,\n        subsets: Iterable[IPNetwork] = (UNIVERSE_SUBSET,),\n    ) -&gt; Iterator[dict]:\n        \"\"\"\n        Execute the query and return each row as a dict, as they are received from the database.\n        \"\"\"\n        for subset in subsets:\n            for i, statement in enumerate(self.statements(measurement_id, subset)):\n                with LoggingTimer(\n                    logger,\n                    f\"query={self.name}#{i} measurement_id={measurement_id} subset={subset} limit={limit}\",\n                ):\n                    settings = dict(\n                        limit=limit[0] if limit else 0,\n                        offset=limit[1] if limit else 0,\n                    )\n                    yield from client.iter_json(statement, data=data, settings=settings)\n\n    def execute_concurrent(\n        self,\n        client: ClickHouseClient,\n        measurement_id: str,\n        *,\n        subsets: Iterable[IPNetwork] = (UNIVERSE_SUBSET,),\n        limit: tuple[int, int] | None = None,\n        concurrent_requests: int = max(available_cpus() // 8, 1),\n    ) -&gt; None:\n        \"\"\"\n        Execute the query concurrently on the specified subsets.\n        \"\"\"\n        logger.info(\"query=%s concurrent_requests=%s\", self.name, concurrent_requests)\n        with ThreadPoolExecutor(concurrent_requests) as executor:\n            futures = [\n                executor.submit(\n                    self.execute,\n                    client=client,\n                    measurement_id=measurement_id,\n                    subsets=(subset,),\n                    limit=limit,\n                )\n                for subset in subsets\n            ]\n            for future in as_completed(futures):\n                future.result()\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.Query.execute","title":"<code>execute(client, measurement_id, *, data=None, limit=None, subsets=(UNIVERSE_SUBSET))</code>","text":"<p>Execute the query and return each row as a dict. Args:     client: ClickHouse client.     measurement_id: Measurement id.     data: str or bytes iterator containing data to send.     limit: (limit, offset) tuple.     subsets: Iterable of IP networks on which to execute the query independently.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>def execute(\n    self,\n    client: ClickHouseClient,\n    measurement_id: str,\n    *,\n    data: Any | None = None,\n    limit: tuple[int, int] | None = None,\n    subsets: Iterable[IPNetwork] = (UNIVERSE_SUBSET,),\n) -&gt; list[dict]:\n    \"\"\"\n    Execute the query and return each row as a dict.\n    Args:\n        client: ClickHouse client.\n        measurement_id: Measurement id.\n        data: str or bytes iterator containing data to send.\n        limit: (limit, offset) tuple.\n        subsets: Iterable of IP networks on which to execute the query independently.\n    \"\"\"\n    rows = []\n    for subset in subsets:\n        for i, statement in enumerate(self.statements(measurement_id, subset)):\n            with LoggingTimer(\n                logger,\n                f\"query={self.name}#{i} measurement_id={measurement_id} subset={subset} limit={limit}\",\n            ):\n                settings = dict(\n                    limit=limit[0] if limit else 0,\n                    offset=limit[1] if limit else 0,\n                )\n                rows += client.json(statement, data=data, settings=settings)\n    return rows\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.Query.execute_concurrent","title":"<code>execute_concurrent(client, measurement_id, *, subsets=(UNIVERSE_SUBSET), limit=None, concurrent_requests=max(available_cpus() // 8, 1))</code>","text":"<p>Execute the query concurrently on the specified subsets.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>def execute_concurrent(\n    self,\n    client: ClickHouseClient,\n    measurement_id: str,\n    *,\n    subsets: Iterable[IPNetwork] = (UNIVERSE_SUBSET,),\n    limit: tuple[int, int] | None = None,\n    concurrent_requests: int = max(available_cpus() // 8, 1),\n) -&gt; None:\n    \"\"\"\n    Execute the query concurrently on the specified subsets.\n    \"\"\"\n    logger.info(\"query=%s concurrent_requests=%s\", self.name, concurrent_requests)\n    with ThreadPoolExecutor(concurrent_requests) as executor:\n        futures = [\n            executor.submit(\n                self.execute,\n                client=client,\n                measurement_id=measurement_id,\n                subsets=(subset,),\n                limit=limit,\n            )\n            for subset in subsets\n        ]\n        for future in as_completed(futures):\n            future.result()\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.Query.execute_iter","title":"<code>execute_iter(client, measurement_id, *, data=None, limit=None, subsets=(UNIVERSE_SUBSET))</code>","text":"<p>Execute the query and return each row as a dict, as they are received from the database.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>def execute_iter(\n    self,\n    client: ClickHouseClient,\n    measurement_id: str,\n    *,\n    data: Any | None = None,\n    limit: tuple[int, int] | None = None,\n    subsets: Iterable[IPNetwork] = (UNIVERSE_SUBSET,),\n) -&gt; Iterator[dict]:\n    \"\"\"\n    Execute the query and return each row as a dict, as they are received from the database.\n    \"\"\"\n    for subset in subsets:\n        for i, statement in enumerate(self.statements(measurement_id, subset)):\n            with LoggingTimer(\n                logger,\n                f\"query={self.name}#{i} measurement_id={measurement_id} subset={subset} limit={limit}\",\n            ):\n                settings = dict(\n                    limit=limit[0] if limit else 0,\n                    offset=limit[1] if limit else 0,\n                )\n                yield from client.iter_json(statement, data=data, settings=settings)\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.ResultsQuery","title":"<code>ResultsQuery</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Query</code></p> <p>Base class for queries on the results table.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>@dataclass(frozen=True)\nclass ResultsQuery(Query):\n    \"\"\"Base class for queries on the results table.\"\"\"\n\n    filter_destination_host: bool = True\n    \"If true, ignore the replies from the destination host.\"\n\n    filter_destination_prefix: bool = True\n    \"If true, ignore the replies from the destination prefix.\"\n\n    filter_private: bool = True\n    \"If true, ignore the replies from private IP addresses.\"\n\n    filter_invalid_probe_protocol: bool = True\n    \"If true, ignore the replies with probe protocol \u2260 ICMP, ICMPv6 or UDP.\"\n\n    time_exceeded_only: bool = True\n    \"If true, ignore non ICMP time exceeded replies.\"\n\n    probe_protocol: int | None = None\n    \"If specified, keep only the replies to probes sent with this protocol.\"\n\n    probe_src_addr: str | None = None\n    \"\"\"\n    If specified, keep only the replies to probes sent by this address.\n    This filter is relatively costly (IPv6 comparison on each row).\n    \"\"\"\n\n    round_eq: int | None = None\n    \"If specified, keep only the replies from this round.\"\n\n    round_leq: int | None = None\n    \"If specified, keep only the replies from this round or before.\"\n\n    def filters(self, subset: IPNetwork) -&gt; str:\n        \"\"\"`WHERE` clause common to all queries on the results table.\"\"\"\n        s = []\n        if subset != UNIVERSE_SUBSET:\n            s += [ip_in(\"probe_dst_prefix\", subset)]\n        if self.probe_protocol:\n            s += [eq(\"probe_protocol\", self.probe_protocol)]\n        if self.probe_src_addr:\n            s += [ip_eq(\"probe_src_addr\", self.probe_src_addr)]\n        if self.round_eq:\n            s += [eq(\"round\", self.round_eq)]\n        if self.round_leq:\n            s += [leq(\"round\", self.round_leq)]\n        if self.filter_destination_host:\n            s += [not_(\"destination_host_reply\")]\n        if self.filter_destination_prefix:\n            s += [not_(\"destination_prefix_reply\")]\n        if self.filter_private:\n            s += [not_(\"private_probe_dst_prefix\"), not_(\"private_reply_src_addr\")]\n        if self.time_exceeded_only:\n            s += [\"time_exceeded_reply\"]\n        if self.filter_invalid_probe_protocol:\n            s += [\"valid_probe_protocol\"]\n        return reduce(and_, s or [\"1\"])\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.ResultsQuery.filter_destination_host","title":"<code>filter_destination_host: bool = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, ignore the replies from the destination host.</p>"},{"location":"reference/queries/#diamond_miner.queries.ResultsQuery.filter_destination_prefix","title":"<code>filter_destination_prefix: bool = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, ignore the replies from the destination prefix.</p>"},{"location":"reference/queries/#diamond_miner.queries.ResultsQuery.filter_invalid_probe_protocol","title":"<code>filter_invalid_probe_protocol: bool = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, ignore the replies with probe protocol \u2260 ICMP, ICMPv6 or UDP.</p>"},{"location":"reference/queries/#diamond_miner.queries.ResultsQuery.filter_private","title":"<code>filter_private: bool = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, ignore the replies from private IP addresses.</p>"},{"location":"reference/queries/#diamond_miner.queries.ResultsQuery.probe_protocol","title":"<code>probe_protocol: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the replies to probes sent with this protocol.</p>"},{"location":"reference/queries/#diamond_miner.queries.ResultsQuery.probe_src_addr","title":"<code>probe_src_addr: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the replies to probes sent by this address. This filter is relatively costly (IPv6 comparison on each row).</p>"},{"location":"reference/queries/#diamond_miner.queries.ResultsQuery.round_eq","title":"<code>round_eq: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the replies from this round.</p>"},{"location":"reference/queries/#diamond_miner.queries.ResultsQuery.round_leq","title":"<code>round_leq: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If specified, keep only the replies from this round or before.</p>"},{"location":"reference/queries/#diamond_miner.queries.ResultsQuery.time_exceeded_only","title":"<code>time_exceeded_only: bool = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If true, ignore non ICMP time exceeded replies.</p>"},{"location":"reference/queries/#diamond_miner.queries.ResultsQuery.filters","title":"<code>filters(subset)</code>","text":"<p><code>WHERE</code> clause common to all queries on the results table.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>def filters(self, subset: IPNetwork) -&gt; str:\n    \"\"\"`WHERE` clause common to all queries on the results table.\"\"\"\n    s = []\n    if subset != UNIVERSE_SUBSET:\n        s += [ip_in(\"probe_dst_prefix\", subset)]\n    if self.probe_protocol:\n        s += [eq(\"probe_protocol\", self.probe_protocol)]\n    if self.probe_src_addr:\n        s += [ip_eq(\"probe_src_addr\", self.probe_src_addr)]\n    if self.round_eq:\n        s += [eq(\"round\", self.round_eq)]\n    if self.round_leq:\n        s += [leq(\"round\", self.round_leq)]\n    if self.filter_destination_host:\n        s += [not_(\"destination_host_reply\")]\n    if self.filter_destination_prefix:\n        s += [not_(\"destination_prefix_reply\")]\n    if self.filter_private:\n        s += [not_(\"private_probe_dst_prefix\"), not_(\"private_reply_src_addr\")]\n    if self.time_exceeded_only:\n        s += [\"time_exceeded_reply\"]\n    if self.filter_invalid_probe_protocol:\n        s += [\"valid_probe_protocol\"]\n    return reduce(and_, s or [\"1\"])\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.StoragePolicy","title":"<code>StoragePolicy</code>  <code>dataclass</code>","text":"<ul> <li>TTL for Columns and Tables</li> <li>Using Multiple Block Devices for Data Storage</li> </ul> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>@dataclass(frozen=True)\nclass StoragePolicy:\n    \"\"\"\n    - [TTL for Columns and Tables](https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/mergetree/#table_engine-mergetree-ttl)\n    - [Using Multiple Block Devices for Data Storage](https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/mergetree/#table_engine-mergetree-multiple-volumes)\n    \"\"\"\n\n    name: str = \"default\"\n    \"\"\"Name of the ClickHouse storage policy to use for the table.\"\"\"\n    archive_to: str = \"default\"\n    \"\"\"Name of the ClickHouse archive volume.\"\"\"\n    archive_on: datetime = datetime(2100, 1, 1)\n    \"\"\"Date at which the table will be moved to the archive volume.\"\"\"\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.StoragePolicy.archive_on","title":"<code>archive_on: datetime = datetime(2100, 1, 1)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Date at which the table will be moved to the archive volume.</p>"},{"location":"reference/queries/#diamond_miner.queries.StoragePolicy.archive_to","title":"<code>archive_to: str = 'default'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Name of the ClickHouse archive volume.</p>"},{"location":"reference/queries/#diamond_miner.queries.StoragePolicy.name","title":"<code>name: str = 'default'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Name of the ClickHouse storage policy to use for the table.</p>"},{"location":"reference/queries/#diamond_miner.queries.links_table","title":"<code>links_table(measurement_id)</code>","text":"<p>Returns the name of the links table.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>def links_table(measurement_id: str) -&gt; str:\n    \"\"\"Returns the name of the links table.\"\"\"\n    return f\"links__{measurement_id}\".replace(\"-\", \"_\")\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.prefixes_table","title":"<code>prefixes_table(measurement_id)</code>","text":"<p>Returns the name of the prefixes table.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>def prefixes_table(measurement_id: str) -&gt; str:\n    \"\"\"Returns the name of the prefixes table.\"\"\"\n    return f\"prefixes__{measurement_id}\".replace(\"-\", \"_\")\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.probes_table","title":"<code>probes_table(measurement_id)</code>","text":"<p>Returns the name of the probes table.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>def probes_table(measurement_id: str) -&gt; str:\n    \"\"\"Returns the name of the probes table.\"\"\"\n    return f\"probes__{measurement_id}\".replace(\"-\", \"_\")\n</code></pre>"},{"location":"reference/queries/#diamond_miner.queries.results_table","title":"<code>results_table(measurement_id)</code>","text":"<p>Returns the name of the results table.</p> Source code in <code>diamond_miner/queries/query.py</code> <pre><code>def results_table(measurement_id: str) -&gt; str:\n    \"\"\"Returns the name of the results table.\"\"\"\n    return f\"results__{measurement_id}\".replace(\"-\", \"_\")\n</code></pre>"}]}